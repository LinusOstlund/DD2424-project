Loading data...
Creating splits...
Creating model...
TransfModel(
  (embedding): Embedding(63, 64)
  (encoder_layer): TransformerEncoderLayer(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
    )
    (linear1): Linear(in_features=64, out_features=64, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
    (linear2): Linear(in_features=64, out_features=64, bias=True)
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=64, bias=True)
        (dropout): Dropout(p=0.2, inplace=False)
        (linear2): Linear(in_features=64, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (positional_encoding): PositionalEncoding(
    (dropout): Dropout(p=0.2, inplace=False)
  )
  (prediction_layer): Linear(in_features=64, out_features=63, bias=True)
  (softmax): Softmax(dim=-1)
)
Using CUDA.
Training started.
TRAIN	EPOCH:0/200	LOSS:1.858192
VAL	EPOCH:0/200	LOSS:1.507594
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:1/200	LOSS:1.532447
VAL	EPOCH:1/200	LOSS:1.185104
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:2/200	LOSS:1.367078
VAL	EPOCH:2/200	LOSS:1.041552
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:3/200	LOSS:1.286795
VAL	EPOCH:3/200	LOSS:1.001096
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:4/200	LOSS:1.250236
VAL	EPOCH:4/200	LOSS:0.974298
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:5/200	LOSS:1.226059
VAL	EPOCH:5/200	LOSS:0.960199
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:6/200	LOSS:1.217135
VAL	EPOCH:6/200	LOSS:0.941373
TRAIN	EPOCH:7/200	LOSS:1.201394
VAL	EPOCH:7/200	LOSS:0.9443
TRAIN	EPOCH:8/200	LOSS:1.189029
VAL	EPOCH:8/200	LOSS:0.933346
TRAIN	EPOCH:9/200	LOSS:1.186793
VAL	EPOCH:9/200	LOSS:0.930438
TRAIN	EPOCH:10/200	LOSS:1.181263
VAL	EPOCH:10/200	LOSS:0.907211
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:11/200	LOSS:1.174862
VAL	EPOCH:11/200	LOSS:0.917426
TRAIN	EPOCH:12/200	LOSS:1.169872
VAL	EPOCH:12/200	LOSS:0.920823
TRAIN	EPOCH:13/200	LOSS:1.171422
VAL	EPOCH:13/200	LOSS:0.904535
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:14/200	LOSS:1.165334
VAL	EPOCH:14/200	LOSS:0.898418
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:15/200	LOSS:1.163495
VAL	EPOCH:15/200	LOSS:0.886223
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:16/200	LOSS:1.158098
VAL	EPOCH:16/200	LOSS:0.889781
TRAIN	EPOCH:17/200	LOSS:1.161655
VAL	EPOCH:17/200	LOSS:0.902502
TRAIN	EPOCH:18/200	LOSS:1.157673
VAL	EPOCH:18/200	LOSS:0.893652
TRAIN	EPOCH:19/200	LOSS:1.160014
VAL	EPOCH:19/200	LOSS:0.90795
TRAIN	EPOCH:20/200	LOSS:1.154961
VAL	EPOCH:20/200	LOSS:0.887941
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:21/200	LOSS:1.155581
VAL	EPOCH:21/200	LOSS:0.900528
TRAIN	EPOCH:22/200	LOSS:1.156283
VAL	EPOCH:22/200	LOSS:0.898069
TRAIN	EPOCH:23/200	LOSS:1.154358
VAL	EPOCH:23/200	LOSS:0.895939
TRAIN	EPOCH:24/200	LOSS:1.154666
VAL	EPOCH:24/200	LOSS:0.903787
TRAIN	EPOCH:25/200	LOSS:1.1499
VAL	EPOCH:25/200	LOSS:0.887264
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:26/200	LOSS:1.147139
VAL	EPOCH:26/200	LOSS:0.893305
TRAIN	EPOCH:27/200	LOSS:1.142704
VAL	EPOCH:27/200	LOSS:0.891637
TRAIN	EPOCH:28/200	LOSS:1.145181
VAL	EPOCH:28/200	LOSS:0.869134
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:29/200	LOSS:1.144869
VAL	EPOCH:29/200	LOSS:0.882761
TRAIN	EPOCH:30/200	LOSS:1.146364
VAL	EPOCH:30/200	LOSS:0.891949
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:31/200	LOSS:1.146304
VAL	EPOCH:31/200	LOSS:0.883111
TRAIN	EPOCH:32/200	LOSS:1.144077
VAL	EPOCH:32/200	LOSS:0.882749
TRAIN	EPOCH:33/200	LOSS:1.151484
VAL	EPOCH:33/200	LOSS:0.879809
TRAIN	EPOCH:34/200	LOSS:1.149516
VAL	EPOCH:34/200	LOSS:0.874572
TRAIN	EPOCH:35/200	LOSS:1.143031
VAL	EPOCH:35/200	LOSS:0.87653
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:36/200	LOSS:1.141728
VAL	EPOCH:36/200	LOSS:0.879376
TRAIN	EPOCH:37/200	LOSS:1.142814
VAL	EPOCH:37/200	LOSS:0.885919
TRAIN	EPOCH:38/200	LOSS:1.143283
VAL	EPOCH:38/200	LOSS:0.891353
TRAIN	EPOCH:39/200	LOSS:1.14336
VAL	EPOCH:39/200	LOSS:0.878039
TRAIN	EPOCH:40/200	LOSS:1.142911
VAL	EPOCH:40/200	LOSS:0.876597
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:41/200	LOSS:1.141642
VAL	EPOCH:41/200	LOSS:0.908455
TRAIN	EPOCH:42/200	LOSS:1.140981
VAL	EPOCH:42/200	LOSS:0.884336
TRAIN	EPOCH:43/200	LOSS:1.139953
VAL	EPOCH:43/200	LOSS:0.872156
TRAIN	EPOCH:44/200	LOSS:1.141259
VAL	EPOCH:44/200	LOSS:0.868323
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:45/200	LOSS:1.140399
VAL	EPOCH:45/200	LOSS:0.883418
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:46/200	LOSS:1.141263
VAL	EPOCH:46/200	LOSS:0.871672
TRAIN	EPOCH:47/200	LOSS:1.144146
VAL	EPOCH:47/200	LOSS:0.884647
TRAIN	EPOCH:48/200	LOSS:1.139413
VAL	EPOCH:48/200	LOSS:0.878697
TRAIN	EPOCH:49/200	LOSS:1.138712
VAL	EPOCH:49/200	LOSS:0.874197
TRAIN	EPOCH:50/200	LOSS:1.138651
VAL	EPOCH:50/200	LOSS:0.880587
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:51/200	LOSS:1.146113
VAL	EPOCH:51/200	LOSS:0.898036
TRAIN	EPOCH:52/200	LOSS:1.139373
VAL	EPOCH:52/200	LOSS:0.871818
TRAIN	EPOCH:53/200	LOSS:1.139258
VAL	EPOCH:53/200	LOSS:0.881133
TRAIN	EPOCH:54/200	LOSS:1.138246
VAL	EPOCH:54/200	LOSS:0.893669
TRAIN	EPOCH:55/200	LOSS:1.137415
VAL	EPOCH:55/200	LOSS:0.8686
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:56/200	LOSS:1.136637
VAL	EPOCH:56/200	LOSS:0.874882
TRAIN	EPOCH:57/200	LOSS:1.136202
VAL	EPOCH:57/200	LOSS:0.879747
TRAIN	EPOCH:58/200	LOSS:1.136943
VAL	EPOCH:58/200	LOSS:0.878594
TRAIN	EPOCH:59/200	LOSS:1.137375
VAL	EPOCH:59/200	LOSS:0.875971
TRAIN	EPOCH:60/200	LOSS:1.136227
VAL	EPOCH:60/200	LOSS:0.878486
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:61/200	LOSS:1.138222
VAL	EPOCH:61/200	LOSS:0.87433
TRAIN	EPOCH:62/200	LOSS:1.134553
VAL	EPOCH:62/200	LOSS:0.867838
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:63/200	LOSS:1.136699
VAL	EPOCH:63/200	LOSS:0.880291
TRAIN	EPOCH:64/200	LOSS:1.137101
VAL	EPOCH:64/200	LOSS:0.879465
TRAIN	EPOCH:65/200	LOSS:1.141763
VAL	EPOCH:65/200	LOSS:0.878104
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:66/200	LOSS:1.13609
VAL	EPOCH:66/200	LOSS:0.871434
TRAIN	EPOCH:67/200	LOSS:1.136937
VAL	EPOCH:67/200	LOSS:0.882796
TRAIN	EPOCH:68/200	LOSS:1.135133
VAL	EPOCH:68/200	LOSS:0.880996
TRAIN	EPOCH:69/200	LOSS:1.139419
VAL	EPOCH:69/200	LOSS:0.881112
TRAIN	EPOCH:70/200	LOSS:1.132983
VAL	EPOCH:70/200	LOSS:0.883954
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:71/200	LOSS:1.142081
VAL	EPOCH:71/200	LOSS:0.900001
TRAIN	EPOCH:72/200	LOSS:1.141643
VAL	EPOCH:72/200	LOSS:0.878562
TRAIN	EPOCH:73/200	LOSS:1.13452
VAL	EPOCH:73/200	LOSS:0.877911
TRAIN	EPOCH:74/200	LOSS:1.133243
VAL	EPOCH:74/200	LOSS:0.867907
TRAIN	EPOCH:75/200	LOSS:1.134164
VAL	EPOCH:75/200	LOSS:0.869528
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:76/200	LOSS:1.135438
VAL	EPOCH:76/200	LOSS:0.882291
TRAIN	EPOCH:77/200	LOSS:1.136235
VAL	EPOCH:77/200	LOSS:0.882559
TRAIN	EPOCH:78/200	LOSS:1.138439
VAL	EPOCH:78/200	LOSS:0.870285
TRAIN	EPOCH:79/200	LOSS:1.137151
VAL	EPOCH:79/200	LOSS:0.880335
TRAIN	EPOCH:80/200	LOSS:1.133935
VAL	EPOCH:80/200	LOSS:0.894705
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:81/200	LOSS:1.136955
VAL	EPOCH:81/200	LOSS:0.865418
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:82/200	LOSS:1.129091
VAL	EPOCH:82/200	LOSS:0.882927
TRAIN	EPOCH:83/200	LOSS:1.133472
VAL	EPOCH:83/200	LOSS:0.883178
TRAIN	EPOCH:84/200	LOSS:1.131568
VAL	EPOCH:84/200	LOSS:0.864341
TRAIN	EPOCH:85/200	LOSS:1.131105
VAL	EPOCH:85/200	LOSS:0.876025
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:86/200	LOSS:1.130244
VAL	EPOCH:86/200	LOSS:0.87461
TRAIN	EPOCH:87/200	LOSS:1.131201
VAL	EPOCH:87/200	LOSS:0.860232
TRAIN	EPOCH:88/200	LOSS:1.13458
VAL	EPOCH:88/200	LOSS:0.869011
TRAIN	EPOCH:89/200	LOSS:1.131698
VAL	EPOCH:89/200	LOSS:0.873574
TRAIN	EPOCH:90/200	LOSS:1.135038
VAL	EPOCH:90/200	LOSS:0.875298
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:91/200	LOSS:1.135607
VAL	EPOCH:91/200	LOSS:0.863486
TRAIN	EPOCH:92/200	LOSS:1.132715
VAL	EPOCH:92/200	LOSS:0.864674
TRAIN	EPOCH:93/200	LOSS:1.13267
VAL	EPOCH:93/200	LOSS:0.875957
TRAIN	EPOCH:94/200	LOSS:1.131944
VAL	EPOCH:94/200	LOSS:0.864898
TRAIN	EPOCH:95/200	LOSS:1.13134
VAL	EPOCH:95/200	LOSS:0.872451
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:96/200	LOSS:1.132889
VAL	EPOCH:96/200	LOSS:0.87464
TRAIN	EPOCH:97/200	LOSS:1.127887
VAL	EPOCH:97/200	LOSS:0.874256
TRAIN	EPOCH:98/200	LOSS:1.132952
VAL	EPOCH:98/200	LOSS:0.889872
TRAIN	EPOCH:99/200	LOSS:1.131292
VAL	EPOCH:99/200	LOSS:0.880066
TRAIN	EPOCH:100/200	LOSS:1.132906
VAL	EPOCH:100/200	LOSS:0.87581
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:101/200	LOSS:1.133751
VAL	EPOCH:101/200	LOSS:0.881358
TRAIN	EPOCH:102/200	LOSS:1.133087
VAL	EPOCH:102/200	LOSS:0.868145
TRAIN	EPOCH:103/200	LOSS:1.134094
VAL	EPOCH:103/200	LOSS:0.873361
TRAIN	EPOCH:104/200	LOSS:1.131646
VAL	EPOCH:104/200	LOSS:0.892205
TRAIN	EPOCH:105/200	LOSS:1.131998
VAL	EPOCH:105/200	LOSS:0.877363
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:106/200	LOSS:1.133543
VAL	EPOCH:106/200	LOSS:0.876126
TRAIN	EPOCH:107/200	LOSS:1.135712
VAL	EPOCH:107/200	LOSS:0.868642
TRAIN	EPOCH:108/200	LOSS:1.132486
VAL	EPOCH:108/200	LOSS:0.862354
TRAIN	EPOCH:109/200	LOSS:1.131606
VAL	EPOCH:109/200	LOSS:0.87822
TRAIN	EPOCH:110/200	LOSS:1.133856
VAL	EPOCH:110/200	LOSS:0.881294
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:111/200	LOSS:1.133452
VAL	EPOCH:111/200	LOSS:0.880209
TRAIN	EPOCH:112/200	LOSS:1.128942
VAL	EPOCH:112/200	LOSS:0.865377
TRAIN	EPOCH:113/200	LOSS:1.132182
VAL	EPOCH:113/200	LOSS:0.869125
TRAIN	EPOCH:114/200	LOSS:1.131367
VAL	EPOCH:114/200	LOSS:0.877176
TRAIN	EPOCH:115/200	LOSS:1.133443
VAL	EPOCH:115/200	LOSS:0.871998
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:116/200	LOSS:1.130064
VAL	EPOCH:116/200	LOSS:0.871745
TRAIN	EPOCH:117/200	LOSS:1.127583
VAL	EPOCH:117/200	LOSS:0.878251
TRAIN	EPOCH:118/200	LOSS:1.133105
VAL	EPOCH:118/200	LOSS:0.884728
TRAIN	EPOCH:119/200	LOSS:1.128542
VAL	EPOCH:119/200	LOSS:0.873026
TRAIN	EPOCH:120/200	LOSS:1.130155
VAL	EPOCH:120/200	LOSS:0.884484
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:121/200	LOSS:1.146455
VAL	EPOCH:121/200	LOSS:0.88368
TRAIN	EPOCH:122/200	LOSS:1.133641
VAL	EPOCH:122/200	LOSS:0.871259
TRAIN	EPOCH:123/200	LOSS:1.126864
VAL	EPOCH:123/200	LOSS:0.877362
TRAIN	EPOCH:124/200	LOSS:1.130667
VAL	EPOCH:124/200	LOSS:0.874742
TRAIN	EPOCH:125/200	LOSS:1.129037
VAL	EPOCH:125/200	LOSS:0.879468
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:126/200	LOSS:1.13119
VAL	EPOCH:126/200	LOSS:0.867661
TRAIN	EPOCH:127/200	LOSS:1.131301
VAL	EPOCH:127/200	LOSS:0.875761
TRAIN	EPOCH:128/200	LOSS:1.128788
VAL	EPOCH:128/200	LOSS:0.877046
TRAIN	EPOCH:129/200	LOSS:1.138773
VAL	EPOCH:129/200	LOSS:0.867394
TRAIN	EPOCH:130/200	LOSS:1.133715
VAL	EPOCH:130/200	LOSS:0.875919
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:131/200	LOSS:1.128809
VAL	EPOCH:131/200	LOSS:0.870269
TRAIN	EPOCH:132/200	LOSS:1.128705
VAL	EPOCH:132/200	LOSS:0.867579
TRAIN	EPOCH:133/200	LOSS:1.130172
VAL	EPOCH:133/200	LOSS:0.880036
TRAIN	EPOCH:134/200	LOSS:1.130805
VAL	EPOCH:134/200	LOSS:0.870799
TRAIN	EPOCH:135/200	LOSS:1.132758
VAL	EPOCH:135/200	LOSS:0.871121
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:136/200	LOSS:1.128751
VAL	EPOCH:136/200	LOSS:0.87327
TRAIN	EPOCH:137/200	LOSS:1.127075
VAL	EPOCH:137/200	LOSS:0.889054
TRAIN	EPOCH:138/200	LOSS:1.131607
VAL	EPOCH:138/200	LOSS:0.874365
TRAIN	EPOCH:139/200	LOSS:1.131463
VAL	EPOCH:139/200	LOSS:0.868882
TRAIN	EPOCH:140/200	LOSS:1.129603
VAL	EPOCH:140/200	LOSS:0.868832
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:141/200	LOSS:1.132123
VAL	EPOCH:141/200	LOSS:0.875725
TRAIN	EPOCH:142/200	LOSS:1.130594
VAL	EPOCH:142/200	LOSS:0.867272
TRAIN	EPOCH:143/200	LOSS:1.129277
VAL	EPOCH:143/200	LOSS:0.879755
TRAIN	EPOCH:144/200	LOSS:1.132684
VAL	EPOCH:144/200	LOSS:0.8786
TRAIN	EPOCH:145/200	LOSS:1.130399
VAL	EPOCH:145/200	LOSS:0.913669
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:146/200	LOSS:1.146727
VAL	EPOCH:146/200	LOSS:0.887416
TRAIN	EPOCH:147/200	LOSS:1.131144
VAL	EPOCH:147/200	LOSS:0.876369
TRAIN	EPOCH:148/200	LOSS:1.130826
VAL	EPOCH:148/200	LOSS:0.86598
TRAIN	EPOCH:149/200	LOSS:1.12794
VAL	EPOCH:149/200	LOSS:0.873467
TRAIN	EPOCH:150/200	LOSS:1.127359
VAL	EPOCH:150/200	LOSS:0.872779
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:151/200	LOSS:1.125423
VAL	EPOCH:151/200	LOSS:0.892042
TRAIN	EPOCH:152/200	LOSS:1.132146
VAL	EPOCH:152/200	LOSS:0.874372
TRAIN	EPOCH:153/200	LOSS:1.128608
VAL	EPOCH:153/200	LOSS:0.87326
TRAIN	EPOCH:154/200	LOSS:1.130291
VAL	EPOCH:154/200	LOSS:0.871921
TRAIN	EPOCH:155/200	LOSS:1.130431
VAL	EPOCH:155/200	LOSS:0.867294
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:156/200	LOSS:1.126634
VAL	EPOCH:156/200	LOSS:0.887058
TRAIN	EPOCH:157/200	LOSS:1.128875
VAL	EPOCH:157/200	LOSS:0.873767
TRAIN	EPOCH:158/200	LOSS:1.129786
VAL	EPOCH:158/200	LOSS:0.861934
TRAIN	EPOCH:159/200	LOSS:1.127355
VAL	EPOCH:159/200	LOSS:0.859321
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/best.pytorch
TRAIN	EPOCH:160/200	LOSS:1.126113
VAL	EPOCH:160/200	LOSS:0.876213
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:161/200	LOSS:1.128576
VAL	EPOCH:161/200	LOSS:0.890283
TRAIN	EPOCH:162/200	LOSS:1.130328
VAL	EPOCH:162/200	LOSS:0.857259
TRAIN	EPOCH:163/200	LOSS:1.129972
VAL	EPOCH:163/200	LOSS:0.872975
TRAIN	EPOCH:164/200	LOSS:1.129442
VAL	EPOCH:164/200	LOSS:0.8678
TRAIN	EPOCH:165/200	LOSS:1.129914
VAL	EPOCH:165/200	LOSS:0.868758
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:166/200	LOSS:1.133071
VAL	EPOCH:166/200	LOSS:0.879072
TRAIN	EPOCH:167/200	LOSS:1.133087
VAL	EPOCH:167/200	LOSS:0.86473
TRAIN	EPOCH:168/200	LOSS:1.128871
VAL	EPOCH:168/200	LOSS:0.875541
TRAIN	EPOCH:169/200	LOSS:1.130351
VAL	EPOCH:169/200	LOSS:0.878207
TRAIN	EPOCH:170/200	LOSS:1.128261
VAL	EPOCH:170/200	LOSS:0.856084
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:171/200	LOSS:1.130094
VAL	EPOCH:171/200	LOSS:0.870173
TRAIN	EPOCH:172/200	LOSS:1.130054
VAL	EPOCH:172/200	LOSS:0.873709
TRAIN	EPOCH:173/200	LOSS:1.127323
VAL	EPOCH:173/200	LOSS:0.862713
TRAIN	EPOCH:174/200	LOSS:1.130466
VAL	EPOCH:174/200	LOSS:0.866712
TRAIN	EPOCH:175/200	LOSS:1.13204
VAL	EPOCH:175/200	LOSS:0.87647
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:176/200	LOSS:1.130962
VAL	EPOCH:176/200	LOSS:0.864128
TRAIN	EPOCH:177/200	LOSS:1.134544
VAL	EPOCH:177/200	LOSS:0.873831
TRAIN	EPOCH:178/200	LOSS:1.130717
VAL	EPOCH:178/200	LOSS:0.872011
TRAIN	EPOCH:179/200	LOSS:1.127991
VAL	EPOCH:179/200	LOSS:0.871822
TRAIN	EPOCH:180/200	LOSS:1.129432
VAL	EPOCH:180/200	LOSS:0.878835
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:181/200	LOSS:1.131189
VAL	EPOCH:181/200	LOSS:0.876681
TRAIN	EPOCH:182/200	LOSS:1.126939
VAL	EPOCH:182/200	LOSS:0.872294
TRAIN	EPOCH:183/200	LOSS:1.124869
VAL	EPOCH:183/200	LOSS:0.874318
TRAIN	EPOCH:184/200	LOSS:1.127748
VAL	EPOCH:184/200	LOSS:0.861901
TRAIN	EPOCH:185/200	LOSS:1.12947
VAL	EPOCH:185/200	LOSS:0.873904
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:186/200	LOSS:1.132344
VAL	EPOCH:186/200	LOSS:0.869961
TRAIN	EPOCH:187/200	LOSS:1.128903
VAL	EPOCH:187/200	LOSS:0.866954
TRAIN	EPOCH:188/200	LOSS:1.129421
VAL	EPOCH:188/200	LOSS:0.886213
TRAIN	EPOCH:189/200	LOSS:1.130263
VAL	EPOCH:189/200	LOSS:0.867179
TRAIN	EPOCH:190/200	LOSS:1.128823
VAL	EPOCH:190/200	LOSS:0.865826
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:191/200	LOSS:1.12923
VAL	EPOCH:191/200	LOSS:0.875459
TRAIN	EPOCH:192/200	LOSS:1.126784
VAL	EPOCH:192/200	LOSS:0.858958
TRAIN	EPOCH:193/200	LOSS:1.128042
VAL	EPOCH:193/200	LOSS:0.866271
TRAIN	EPOCH:194/200	LOSS:1.127476
VAL	EPOCH:194/200	LOSS:0.879836
TRAIN	EPOCH:195/200	LOSS:1.12775
VAL	EPOCH:195/200	LOSS:0.868595
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=2/checkpoint.pytorch
TRAIN	EPOCH:196/200	LOSS:1.129102
VAL	EPOCH:196/200	LOSS:0.875894
TRAIN	EPOCH:197/200	LOSS:1.129591
VAL	EPOCH:197/200	LOSS:0.867007
TRAIN	EPOCH:198/200	LOSS:1.128463
VAL	EPOCH:198/200	LOSS:0.88506
TRAIN	EPOCH:199/200	LOSS:1.127019
VAL	EPOCH:199/200	LOSS:0.863102
Loading data...
Creating splits...
Creating model...
TransfModel(
  (embedding): Embedding(63, 64)
  (encoder_layer): TransformerEncoderLayer(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
    )
    (linear1): Linear(in_features=64, out_features=64, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
    (linear2): Linear(in_features=64, out_features=64, bias=True)
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=64, bias=True)
        (dropout): Dropout(p=0.2, inplace=False)
        (linear2): Linear(in_features=64, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (positional_encoding): PositionalEncoding(
    (dropout): Dropout(p=0.2, inplace=False)
  )
  (prediction_layer): Linear(in_features=64, out_features=63, bias=True)
  (softmax): Softmax(dim=-1)
)
Using CUDA.
Training started.
TRAIN	EPOCH:0/200	LOSS:1.841225
VAL	EPOCH:0/200	LOSS:1.496282
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:1/200	LOSS:1.514391
VAL	EPOCH:1/200	LOSS:1.157
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:2/200	LOSS:1.331702
VAL	EPOCH:2/200	LOSS:1.013155
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:3/200	LOSS:1.23835
VAL	EPOCH:3/200	LOSS:0.964694
TRAIN	EPOCH:4/200	LOSS:1.19634
VAL	EPOCH:4/200	LOSS:0.933289
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:5/200	LOSS:1.174073
VAL	EPOCH:5/200	LOSS:0.919665
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:6/200	LOSS:1.157362
VAL	EPOCH:6/200	LOSS:0.909152
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:7/200	LOSS:1.143385
VAL	EPOCH:7/200	LOSS:0.918226
TRAIN	EPOCH:8/200	LOSS:1.137637
VAL	EPOCH:8/200	LOSS:0.899017
TRAIN	EPOCH:9/200	LOSS:1.133775
VAL	EPOCH:9/200	LOSS:0.918345
TRAIN	EPOCH:10/200	LOSS:1.12615
VAL	EPOCH:10/200	LOSS:0.902759
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:11/200	LOSS:1.118434
VAL	EPOCH:11/200	LOSS:0.887237
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:12/200	LOSS:1.113705
VAL	EPOCH:12/200	LOSS:0.898345
TRAIN	EPOCH:13/200	LOSS:1.113545
VAL	EPOCH:13/200	LOSS:0.887259
TRAIN	EPOCH:14/200	LOSS:1.107765
VAL	EPOCH:14/200	LOSS:0.881452
TRAIN	EPOCH:15/200	LOSS:1.102238
VAL	EPOCH:15/200	LOSS:0.863183
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:16/200	LOSS:1.096124
VAL	EPOCH:16/200	LOSS:0.865361
TRAIN	EPOCH:17/200	LOSS:1.100391
VAL	EPOCH:17/200	LOSS:0.866487
TRAIN	EPOCH:18/200	LOSS:1.096667
VAL	EPOCH:18/200	LOSS:0.874263
TRAIN	EPOCH:19/200	LOSS:1.094998
VAL	EPOCH:19/200	LOSS:0.865515
TRAIN	EPOCH:20/200	LOSS:1.0919
VAL	EPOCH:20/200	LOSS:0.856247
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:21/200	LOSS:1.088056
VAL	EPOCH:21/200	LOSS:0.869113
TRAIN	EPOCH:22/200	LOSS:1.089101
VAL	EPOCH:22/200	LOSS:0.854613
TRAIN	EPOCH:23/200	LOSS:1.087095
VAL	EPOCH:23/200	LOSS:0.868395
TRAIN	EPOCH:24/200	LOSS:1.085748
VAL	EPOCH:24/200	LOSS:0.855068
TRAIN	EPOCH:25/200	LOSS:1.081876
VAL	EPOCH:25/200	LOSS:0.861426
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:26/200	LOSS:1.081337
VAL	EPOCH:26/200	LOSS:0.858679
TRAIN	EPOCH:27/200	LOSS:1.077967
VAL	EPOCH:27/200	LOSS:0.858062
TRAIN	EPOCH:28/200	LOSS:1.082672
VAL	EPOCH:28/200	LOSS:0.842489
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:29/200	LOSS:1.078027
VAL	EPOCH:29/200	LOSS:0.846517
TRAIN	EPOCH:30/200	LOSS:1.079412
VAL	EPOCH:30/200	LOSS:0.849591
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:31/200	LOSS:1.083304
VAL	EPOCH:31/200	LOSS:0.852454
TRAIN	EPOCH:32/200	LOSS:1.07504
VAL	EPOCH:32/200	LOSS:0.86406
TRAIN	EPOCH:33/200	LOSS:1.07585
VAL	EPOCH:33/200	LOSS:0.855944
TRAIN	EPOCH:34/200	LOSS:1.08219
VAL	EPOCH:34/200	LOSS:0.856874
TRAIN	EPOCH:35/200	LOSS:1.071261
VAL	EPOCH:35/200	LOSS:0.851172
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:36/200	LOSS:1.076724
VAL	EPOCH:36/200	LOSS:0.844792
TRAIN	EPOCH:37/200	LOSS:1.078749
VAL	EPOCH:37/200	LOSS:0.864328
TRAIN	EPOCH:38/200	LOSS:1.074979
VAL	EPOCH:38/200	LOSS:0.846861
TRAIN	EPOCH:39/200	LOSS:1.070903
VAL	EPOCH:39/200	LOSS:0.860312
TRAIN	EPOCH:40/200	LOSS:1.079036
VAL	EPOCH:40/200	LOSS:0.839649
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:41/200	LOSS:1.070838
VAL	EPOCH:41/200	LOSS:0.844732
TRAIN	EPOCH:42/200	LOSS:1.072607
VAL	EPOCH:42/200	LOSS:0.867554
TRAIN	EPOCH:43/200	LOSS:1.074797
VAL	EPOCH:43/200	LOSS:0.837988
TRAIN	EPOCH:44/200	LOSS:1.073789
VAL	EPOCH:44/200	LOSS:0.838548
TRAIN	EPOCH:45/200	LOSS:1.070401
VAL	EPOCH:45/200	LOSS:0.848611
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:46/200	LOSS:1.073145
VAL	EPOCH:46/200	LOSS:0.836382
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:47/200	LOSS:1.067607
VAL	EPOCH:47/200	LOSS:0.861476
TRAIN	EPOCH:48/200	LOSS:1.069707
VAL	EPOCH:48/200	LOSS:0.847699
TRAIN	EPOCH:49/200	LOSS:1.067374
VAL	EPOCH:49/200	LOSS:0.843623
TRAIN	EPOCH:50/200	LOSS:1.066817
VAL	EPOCH:50/200	LOSS:0.835752
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:51/200	LOSS:1.067783
VAL	EPOCH:51/200	LOSS:0.852166
TRAIN	EPOCH:52/200	LOSS:1.06948
VAL	EPOCH:52/200	LOSS:0.840661
TRAIN	EPOCH:53/200	LOSS:1.066075
VAL	EPOCH:53/200	LOSS:0.845635
TRAIN	EPOCH:54/200	LOSS:1.066063
VAL	EPOCH:54/200	LOSS:0.845695
TRAIN	EPOCH:55/200	LOSS:1.066301
VAL	EPOCH:55/200	LOSS:0.84417
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:56/200	LOSS:1.070574
VAL	EPOCH:56/200	LOSS:0.842883
TRAIN	EPOCH:57/200	LOSS:1.064682
VAL	EPOCH:57/200	LOSS:0.849354
TRAIN	EPOCH:58/200	LOSS:1.06807
VAL	EPOCH:58/200	LOSS:0.83969
TRAIN	EPOCH:59/200	LOSS:1.064415
VAL	EPOCH:59/200	LOSS:0.838713
TRAIN	EPOCH:60/200	LOSS:1.065215
VAL	EPOCH:60/200	LOSS:0.831382
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:61/200	LOSS:1.066031
VAL	EPOCH:61/200	LOSS:0.845631
TRAIN	EPOCH:62/200	LOSS:1.065412
VAL	EPOCH:62/200	LOSS:0.823114
TRAIN	EPOCH:63/200	LOSS:1.059461
VAL	EPOCH:63/200	LOSS:0.849852
TRAIN	EPOCH:64/200	LOSS:1.063498
VAL	EPOCH:64/200	LOSS:0.83219
TRAIN	EPOCH:65/200	LOSS:1.06046
VAL	EPOCH:65/200	LOSS:0.844817
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:66/200	LOSS:1.057547
VAL	EPOCH:66/200	LOSS:0.830688
TRAIN	EPOCH:67/200	LOSS:1.062622
VAL	EPOCH:67/200	LOSS:0.833609
TRAIN	EPOCH:68/200	LOSS:1.060898
VAL	EPOCH:68/200	LOSS:0.83479
TRAIN	EPOCH:69/200	LOSS:1.064177
VAL	EPOCH:69/200	LOSS:0.841471
TRAIN	EPOCH:70/200	LOSS:1.058432
VAL	EPOCH:70/200	LOSS:0.827574
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:71/200	LOSS:1.059877
VAL	EPOCH:71/200	LOSS:0.834187
TRAIN	EPOCH:72/200	LOSS:1.06073
VAL	EPOCH:72/200	LOSS:0.84235
TRAIN	EPOCH:73/200	LOSS:1.063931
VAL	EPOCH:73/200	LOSS:0.843654
TRAIN	EPOCH:74/200	LOSS:1.062254
VAL	EPOCH:74/200	LOSS:0.832585
TRAIN	EPOCH:75/200	LOSS:1.059373
VAL	EPOCH:75/200	LOSS:0.841544
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:76/200	LOSS:1.063184
VAL	EPOCH:76/200	LOSS:0.829975
TRAIN	EPOCH:77/200	LOSS:1.066907
VAL	EPOCH:77/200	LOSS:0.854265
TRAIN	EPOCH:78/200	LOSS:1.065388
VAL	EPOCH:78/200	LOSS:0.844284
TRAIN	EPOCH:79/200	LOSS:1.059234
VAL	EPOCH:79/200	LOSS:0.837958
TRAIN	EPOCH:80/200	LOSS:1.055866
VAL	EPOCH:80/200	LOSS:0.843958
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:81/200	LOSS:1.056797
VAL	EPOCH:81/200	LOSS:0.841367
TRAIN	EPOCH:82/200	LOSS:1.057363
VAL	EPOCH:82/200	LOSS:0.837681
TRAIN	EPOCH:83/200	LOSS:1.062724
VAL	EPOCH:83/200	LOSS:0.835806
TRAIN	EPOCH:84/200	LOSS:1.053021
VAL	EPOCH:84/200	LOSS:0.825911
TRAIN	EPOCH:85/200	LOSS:1.059894
VAL	EPOCH:85/200	LOSS:0.848227
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:86/200	LOSS:1.056434
VAL	EPOCH:86/200	LOSS:0.818782
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:87/200	LOSS:1.056916
VAL	EPOCH:87/200	LOSS:0.828084
TRAIN	EPOCH:88/200	LOSS:1.057783
VAL	EPOCH:88/200	LOSS:0.830137
TRAIN	EPOCH:89/200	LOSS:1.056847
VAL	EPOCH:89/200	LOSS:0.835135
TRAIN	EPOCH:90/200	LOSS:1.054527
VAL	EPOCH:90/200	LOSS:0.827376
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:91/200	LOSS:1.058054
VAL	EPOCH:91/200	LOSS:0.8197
TRAIN	EPOCH:92/200	LOSS:1.056312
VAL	EPOCH:92/200	LOSS:0.832337
TRAIN	EPOCH:93/200	LOSS:1.06342
VAL	EPOCH:93/200	LOSS:0.852798
TRAIN	EPOCH:94/200	LOSS:1.065656
VAL	EPOCH:94/200	LOSS:0.832824
TRAIN	EPOCH:95/200	LOSS:1.054789
VAL	EPOCH:95/200	LOSS:0.834479
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:96/200	LOSS:1.056878
VAL	EPOCH:96/200	LOSS:0.844531
TRAIN	EPOCH:97/200	LOSS:1.055135
VAL	EPOCH:97/200	LOSS:0.833773
TRAIN	EPOCH:98/200	LOSS:1.057038
VAL	EPOCH:98/200	LOSS:0.835728
TRAIN	EPOCH:99/200	LOSS:1.05994
VAL	EPOCH:99/200	LOSS:0.836848
TRAIN	EPOCH:100/200	LOSS:1.06021
VAL	EPOCH:100/200	LOSS:0.83448
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:101/200	LOSS:1.062039
VAL	EPOCH:101/200	LOSS:0.821616
TRAIN	EPOCH:102/200	LOSS:1.058057
VAL	EPOCH:102/200	LOSS:0.853628
TRAIN	EPOCH:103/200	LOSS:1.06474
VAL	EPOCH:103/200	LOSS:0.825983
TRAIN	EPOCH:104/200	LOSS:1.060603
VAL	EPOCH:104/200	LOSS:0.84825
TRAIN	EPOCH:105/200	LOSS:1.073183
VAL	EPOCH:105/200	LOSS:0.848526
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:106/200	LOSS:1.058497
VAL	EPOCH:106/200	LOSS:0.824317
TRAIN	EPOCH:107/200	LOSS:1.058174
VAL	EPOCH:107/200	LOSS:0.824641
TRAIN	EPOCH:108/200	LOSS:1.053943
VAL	EPOCH:108/200	LOSS:0.82386
TRAIN	EPOCH:109/200	LOSS:1.059796
VAL	EPOCH:109/200	LOSS:0.83164
TRAIN	EPOCH:110/200	LOSS:1.063613
VAL	EPOCH:110/200	LOSS:0.830278
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:111/200	LOSS:1.056128
VAL	EPOCH:111/200	LOSS:0.828418
TRAIN	EPOCH:112/200	LOSS:1.053845
VAL	EPOCH:112/200	LOSS:0.832506
TRAIN	EPOCH:113/200	LOSS:1.056911
VAL	EPOCH:113/200	LOSS:0.82757
TRAIN	EPOCH:114/200	LOSS:1.056367
VAL	EPOCH:114/200	LOSS:0.824837
TRAIN	EPOCH:115/200	LOSS:1.058127
VAL	EPOCH:115/200	LOSS:0.837323
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:116/200	LOSS:1.058247
VAL	EPOCH:116/200	LOSS:0.845069
TRAIN	EPOCH:117/200	LOSS:1.057842
VAL	EPOCH:117/200	LOSS:0.842983
TRAIN	EPOCH:118/200	LOSS:1.056584
VAL	EPOCH:118/200	LOSS:0.829076
TRAIN	EPOCH:119/200	LOSS:1.054928
VAL	EPOCH:119/200	LOSS:0.836552
TRAIN	EPOCH:120/200	LOSS:1.057606
VAL	EPOCH:120/200	LOSS:0.851771
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:121/200	LOSS:1.056809
VAL	EPOCH:121/200	LOSS:0.841202
TRAIN	EPOCH:122/200	LOSS:1.055014
VAL	EPOCH:122/200	LOSS:0.825174
TRAIN	EPOCH:123/200	LOSS:1.056207
VAL	EPOCH:123/200	LOSS:0.834399
TRAIN	EPOCH:124/200	LOSS:1.056654
VAL	EPOCH:124/200	LOSS:0.826159
TRAIN	EPOCH:125/200	LOSS:1.05587
VAL	EPOCH:125/200	LOSS:0.83874
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:126/200	LOSS:1.052828
VAL	EPOCH:126/200	LOSS:0.834588
TRAIN	EPOCH:127/200	LOSS:1.050832
VAL	EPOCH:127/200	LOSS:0.828269
TRAIN	EPOCH:128/200	LOSS:1.058168
VAL	EPOCH:128/200	LOSS:0.829858
TRAIN	EPOCH:129/200	LOSS:1.055222
VAL	EPOCH:129/200	LOSS:0.829481
TRAIN	EPOCH:130/200	LOSS:1.05209
VAL	EPOCH:130/200	LOSS:0.821146
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:131/200	LOSS:1.052944
VAL	EPOCH:131/200	LOSS:0.823638
TRAIN	EPOCH:132/200	LOSS:1.051668
VAL	EPOCH:132/200	LOSS:0.827379
TRAIN	EPOCH:133/200	LOSS:1.053551
VAL	EPOCH:133/200	LOSS:0.828623
TRAIN	EPOCH:134/200	LOSS:1.056215
VAL	EPOCH:134/200	LOSS:0.826204
TRAIN	EPOCH:135/200	LOSS:1.055839
VAL	EPOCH:135/200	LOSS:0.829292
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:136/200	LOSS:1.055727
VAL	EPOCH:136/200	LOSS:0.836408
TRAIN	EPOCH:137/200	LOSS:1.057938
VAL	EPOCH:137/200	LOSS:0.83415
TRAIN	EPOCH:138/200	LOSS:1.054781
VAL	EPOCH:138/200	LOSS:0.829128
TRAIN	EPOCH:139/200	LOSS:1.058094
VAL	EPOCH:139/200	LOSS:0.84143
TRAIN	EPOCH:140/200	LOSS:1.055979
VAL	EPOCH:140/200	LOSS:0.81969
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:141/200	LOSS:1.054452
VAL	EPOCH:141/200	LOSS:0.815718
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:142/200	LOSS:1.054099
VAL	EPOCH:142/200	LOSS:0.829315
TRAIN	EPOCH:143/200	LOSS:1.058606
VAL	EPOCH:143/200	LOSS:0.829005
TRAIN	EPOCH:144/200	LOSS:1.055676
VAL	EPOCH:144/200	LOSS:0.822811
TRAIN	EPOCH:145/200	LOSS:1.05843
VAL	EPOCH:145/200	LOSS:0.844706
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:146/200	LOSS:1.054474
VAL	EPOCH:146/200	LOSS:0.822741
TRAIN	EPOCH:147/200	LOSS:1.05617
VAL	EPOCH:147/200	LOSS:0.831212
TRAIN	EPOCH:148/200	LOSS:1.059586
VAL	EPOCH:148/200	LOSS:0.827343
TRAIN	EPOCH:149/200	LOSS:1.058035
VAL	EPOCH:149/200	LOSS:0.825605
TRAIN	EPOCH:150/200	LOSS:1.057841
VAL	EPOCH:150/200	LOSS:0.839452
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:151/200	LOSS:1.05239
VAL	EPOCH:151/200	LOSS:0.830224
TRAIN	EPOCH:152/200	LOSS:1.050273
VAL	EPOCH:152/200	LOSS:0.830034
TRAIN	EPOCH:153/200	LOSS:1.062838
VAL	EPOCH:153/200	LOSS:0.832353
TRAIN	EPOCH:154/200	LOSS:1.059151
VAL	EPOCH:154/200	LOSS:0.84204
TRAIN	EPOCH:155/200	LOSS:1.053204
VAL	EPOCH:155/200	LOSS:0.823575
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:156/200	LOSS:1.053901
VAL	EPOCH:156/200	LOSS:0.823439
TRAIN	EPOCH:157/200	LOSS:1.056377
VAL	EPOCH:157/200	LOSS:0.840922
TRAIN	EPOCH:158/200	LOSS:1.050624
VAL	EPOCH:158/200	LOSS:0.819243
TRAIN	EPOCH:159/200	LOSS:1.053367
VAL	EPOCH:159/200	LOSS:0.823823
TRAIN	EPOCH:160/200	LOSS:1.051486
VAL	EPOCH:160/200	LOSS:0.825274
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:161/200	LOSS:1.049393
VAL	EPOCH:161/200	LOSS:0.84139
TRAIN	EPOCH:162/200	LOSS:1.060187
VAL	EPOCH:162/200	LOSS:0.829892
TRAIN	EPOCH:163/200	LOSS:1.052349
VAL	EPOCH:163/200	LOSS:0.832689
TRAIN	EPOCH:164/200	LOSS:1.054187
VAL	EPOCH:164/200	LOSS:0.822982
TRAIN	EPOCH:165/200	LOSS:1.057909
VAL	EPOCH:165/200	LOSS:0.835651
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:166/200	LOSS:1.055311
VAL	EPOCH:166/200	LOSS:0.825597
TRAIN	EPOCH:167/200	LOSS:1.071091
VAL	EPOCH:167/200	LOSS:0.825177
TRAIN	EPOCH:168/200	LOSS:1.058675
VAL	EPOCH:168/200	LOSS:0.834882
TRAIN	EPOCH:169/200	LOSS:1.057708
VAL	EPOCH:169/200	LOSS:0.832043
TRAIN	EPOCH:170/200	LOSS:1.052003
VAL	EPOCH:170/200	LOSS:0.821419
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:171/200	LOSS:1.051543
VAL	EPOCH:171/200	LOSS:0.840917
TRAIN	EPOCH:172/200	LOSS:1.054155
VAL	EPOCH:172/200	LOSS:0.83141
TRAIN	EPOCH:173/200	LOSS:1.052128
VAL	EPOCH:173/200	LOSS:0.827514
TRAIN	EPOCH:174/200	LOSS:1.054435
VAL	EPOCH:174/200	LOSS:0.824844
TRAIN	EPOCH:175/200	LOSS:1.049234
VAL	EPOCH:175/200	LOSS:0.828191
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:176/200	LOSS:1.054947
VAL	EPOCH:176/200	LOSS:0.817141
TRAIN	EPOCH:177/200	LOSS:1.061071
VAL	EPOCH:177/200	LOSS:0.83119
TRAIN	EPOCH:178/200	LOSS:1.054597
VAL	EPOCH:178/200	LOSS:0.827779
TRAIN	EPOCH:179/200	LOSS:1.055845
VAL	EPOCH:179/200	LOSS:0.834643
TRAIN	EPOCH:180/200	LOSS:1.054316
VAL	EPOCH:180/200	LOSS:0.83607
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:181/200	LOSS:1.050498
VAL	EPOCH:181/200	LOSS:0.838836
TRAIN	EPOCH:182/200	LOSS:1.05258
VAL	EPOCH:182/200	LOSS:0.820462
TRAIN	EPOCH:183/200	LOSS:1.055672
VAL	EPOCH:183/200	LOSS:0.835717
TRAIN	EPOCH:184/200	LOSS:1.057647
VAL	EPOCH:184/200	LOSS:0.835554
TRAIN	EPOCH:185/200	LOSS:1.054507
VAL	EPOCH:185/200	LOSS:0.832314
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:186/200	LOSS:1.05528
VAL	EPOCH:186/200	LOSS:0.832957
TRAIN	EPOCH:187/200	LOSS:1.051049
VAL	EPOCH:187/200	LOSS:0.823276
TRAIN	EPOCH:188/200	LOSS:1.054615
VAL	EPOCH:188/200	LOSS:0.843609
TRAIN	EPOCH:189/200	LOSS:1.060481
VAL	EPOCH:189/200	LOSS:0.83858
TRAIN	EPOCH:190/200	LOSS:1.052401
VAL	EPOCH:190/200	LOSS:0.832234
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:191/200	LOSS:1.051519
VAL	EPOCH:191/200	LOSS:0.833566
TRAIN	EPOCH:192/200	LOSS:1.049166
VAL	EPOCH:192/200	LOSS:0.813549
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:193/200	LOSS:1.054481
VAL	EPOCH:193/200	LOSS:0.827213
TRAIN	EPOCH:194/200	LOSS:1.052618
VAL	EPOCH:194/200	LOSS:0.831365
TRAIN	EPOCH:195/200	LOSS:1.055746
VAL	EPOCH:195/200	LOSS:0.821579
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:196/200	LOSS:1.052606
VAL	EPOCH:196/200	LOSS:0.828211
TRAIN	EPOCH:197/200	LOSS:1.056066
VAL	EPOCH:197/200	LOSS:0.826051
TRAIN	EPOCH:198/200	LOSS:1.056573
VAL	EPOCH:198/200	LOSS:0.850002
TRAIN	EPOCH:199/200	LOSS:1.052824
VAL	EPOCH:199/200	LOSS:0.834772
Loading data...
Creating splits...
Creating model...
TransfModel(
  (embedding): Embedding(63, 64)
  (encoder_layer): TransformerEncoderLayer(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
    )
    (linear1): Linear(in_features=64, out_features=64, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
    (linear2): Linear(in_features=64, out_features=64, bias=True)
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=64, bias=True)
        (dropout): Dropout(p=0.2, inplace=False)
        (linear2): Linear(in_features=64, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (positional_encoding): PositionalEncoding(
    (dropout): Dropout(p=0.2, inplace=False)
  )
  (prediction_layer): Linear(in_features=64, out_features=63, bias=True)
  (softmax): Softmax(dim=-1)
)
Using CUDA.
Training started.
TRAIN	EPOCH:0/200	LOSS:1.841225
VAL	EPOCH:0/200	LOSS:1.496282
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:1/200	LOSS:1.514391
VAL	EPOCH:1/200	LOSS:1.157
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:2/200	LOSS:1.331702
VAL	EPOCH:2/200	LOSS:1.013155
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:3/200	LOSS:1.23835
VAL	EPOCH:3/200	LOSS:0.964694
TRAIN	EPOCH:4/200	LOSS:1.19634
VAL	EPOCH:4/200	LOSS:0.933289
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:5/200	LOSS:1.174073
VAL	EPOCH:5/200	LOSS:0.919665
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:6/200	LOSS:1.157362
VAL	EPOCH:6/200	LOSS:0.909152
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:7/200	LOSS:1.143385
VAL	EPOCH:7/200	LOSS:0.918226
TRAIN	EPOCH:8/200	LOSS:1.137637
VAL	EPOCH:8/200	LOSS:0.899017
TRAIN	EPOCH:9/200	LOSS:1.133775
VAL	EPOCH:9/200	LOSS:0.918345
TRAIN	EPOCH:10/200	LOSS:1.12615
VAL	EPOCH:10/200	LOSS:0.902759
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:11/200	LOSS:1.118434
VAL	EPOCH:11/200	LOSS:0.887237
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:12/200	LOSS:1.113705
VAL	EPOCH:12/200	LOSS:0.898345
TRAIN	EPOCH:13/200	LOSS:1.113545
VAL	EPOCH:13/200	LOSS:0.887259
TRAIN	EPOCH:14/200	LOSS:1.107765
VAL	EPOCH:14/200	LOSS:0.881452
TRAIN	EPOCH:15/200	LOSS:1.102238
VAL	EPOCH:15/200	LOSS:0.863183
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:16/200	LOSS:1.096124
VAL	EPOCH:16/200	LOSS:0.865361
TRAIN	EPOCH:17/200	LOSS:1.100391
VAL	EPOCH:17/200	LOSS:0.866487
TRAIN	EPOCH:18/200	LOSS:1.096667
VAL	EPOCH:18/200	LOSS:0.874263
TRAIN	EPOCH:19/200	LOSS:1.094998
VAL	EPOCH:19/200	LOSS:0.865515
TRAIN	EPOCH:20/200	LOSS:1.0919
VAL	EPOCH:20/200	LOSS:0.856247
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:21/200	LOSS:1.088056
VAL	EPOCH:21/200	LOSS:0.869113
TRAIN	EPOCH:22/200	LOSS:1.089101
VAL	EPOCH:22/200	LOSS:0.854613
TRAIN	EPOCH:23/200	LOSS:1.087095
VAL	EPOCH:23/200	LOSS:0.868394
TRAIN	EPOCH:24/200	LOSS:1.085748
VAL	EPOCH:24/200	LOSS:0.855068
TRAIN	EPOCH:25/200	LOSS:1.081876
VAL	EPOCH:25/200	LOSS:0.861426
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:26/200	LOSS:1.081337
VAL	EPOCH:26/200	LOSS:0.858679
TRAIN	EPOCH:27/200	LOSS:1.077967
VAL	EPOCH:27/200	LOSS:0.858062
TRAIN	EPOCH:28/200	LOSS:1.082672
VAL	EPOCH:28/200	LOSS:0.842489
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:29/200	LOSS:1.078027
VAL	EPOCH:29/200	LOSS:0.846517
TRAIN	EPOCH:30/200	LOSS:1.079412
VAL	EPOCH:30/200	LOSS:0.84959
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:31/200	LOSS:1.083304
VAL	EPOCH:31/200	LOSS:0.852454
TRAIN	EPOCH:32/200	LOSS:1.07504
VAL	EPOCH:32/200	LOSS:0.86406
TRAIN	EPOCH:33/200	LOSS:1.07585
VAL	EPOCH:33/200	LOSS:0.855944
TRAIN	EPOCH:34/200	LOSS:1.08219
VAL	EPOCH:34/200	LOSS:0.856874
TRAIN	EPOCH:35/200	LOSS:1.071261
VAL	EPOCH:35/200	LOSS:0.851172
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:36/200	LOSS:1.076724
VAL	EPOCH:36/200	LOSS:0.844792
TRAIN	EPOCH:37/200	LOSS:1.078749
VAL	EPOCH:37/200	LOSS:0.864328
TRAIN	EPOCH:38/200	LOSS:1.074979
VAL	EPOCH:38/200	LOSS:0.846861
TRAIN	EPOCH:39/200	LOSS:1.070903
VAL	EPOCH:39/200	LOSS:0.860312
TRAIN	EPOCH:40/200	LOSS:1.079036
VAL	EPOCH:40/200	LOSS:0.839649
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:41/200	LOSS:1.070838
VAL	EPOCH:41/200	LOSS:0.844732
TRAIN	EPOCH:42/200	LOSS:1.072607
VAL	EPOCH:42/200	LOSS:0.867554
TRAIN	EPOCH:43/200	LOSS:1.074797
VAL	EPOCH:43/200	LOSS:0.837988
TRAIN	EPOCH:44/200	LOSS:1.073789
VAL	EPOCH:44/200	LOSS:0.838548
TRAIN	EPOCH:45/200	LOSS:1.070401
VAL	EPOCH:45/200	LOSS:0.848611
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:46/200	LOSS:1.073145
VAL	EPOCH:46/200	LOSS:0.836382
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:47/200	LOSS:1.067607
VAL	EPOCH:47/200	LOSS:0.861476
TRAIN	EPOCH:48/200	LOSS:1.069707
VAL	EPOCH:48/200	LOSS:0.847699
TRAIN	EPOCH:49/200	LOSS:1.067374
VAL	EPOCH:49/200	LOSS:0.843623
TRAIN	EPOCH:50/200	LOSS:1.066817
VAL	EPOCH:50/200	LOSS:0.835752
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:51/200	LOSS:1.067784
VAL	EPOCH:51/200	LOSS:0.852166
TRAIN	EPOCH:52/200	LOSS:1.06948
VAL	EPOCH:52/200	LOSS:0.840661
TRAIN	EPOCH:53/200	LOSS:1.066075
VAL	EPOCH:53/200	LOSS:0.845635
TRAIN	EPOCH:54/200	LOSS:1.066063
VAL	EPOCH:54/200	LOSS:0.845695
TRAIN	EPOCH:55/200	LOSS:1.066301
VAL	EPOCH:55/200	LOSS:0.84417
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:56/200	LOSS:1.070573
VAL	EPOCH:56/200	LOSS:0.842883
TRAIN	EPOCH:57/200	LOSS:1.064681
VAL	EPOCH:57/200	LOSS:0.849354
TRAIN	EPOCH:58/200	LOSS:1.06807
VAL	EPOCH:58/200	LOSS:0.83969
TRAIN	EPOCH:59/200	LOSS:1.064415
VAL	EPOCH:59/200	LOSS:0.838713
TRAIN	EPOCH:60/200	LOSS:1.065215
VAL	EPOCH:60/200	LOSS:0.831382
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:61/200	LOSS:1.066031
VAL	EPOCH:61/200	LOSS:0.845631
TRAIN	EPOCH:62/200	LOSS:1.065412
VAL	EPOCH:62/200	LOSS:0.823114
TRAIN	EPOCH:63/200	LOSS:1.059461
VAL	EPOCH:63/200	LOSS:0.849852
TRAIN	EPOCH:64/200	LOSS:1.063498
VAL	EPOCH:64/200	LOSS:0.83219
TRAIN	EPOCH:65/200	LOSS:1.06046
VAL	EPOCH:65/200	LOSS:0.844817
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:66/200	LOSS:1.057547
VAL	EPOCH:66/200	LOSS:0.830688
TRAIN	EPOCH:67/200	LOSS:1.062622
VAL	EPOCH:67/200	LOSS:0.833609
TRAIN	EPOCH:68/200	LOSS:1.060898
VAL	EPOCH:68/200	LOSS:0.83479
TRAIN	EPOCH:69/200	LOSS:1.064177
VAL	EPOCH:69/200	LOSS:0.841471
TRAIN	EPOCH:70/200	LOSS:1.058432
VAL	EPOCH:70/200	LOSS:0.827574
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:71/200	LOSS:1.059877
VAL	EPOCH:71/200	LOSS:0.834187
TRAIN	EPOCH:72/200	LOSS:1.06073
VAL	EPOCH:72/200	LOSS:0.84235
TRAIN	EPOCH:73/200	LOSS:1.063931
VAL	EPOCH:73/200	LOSS:0.843654
TRAIN	EPOCH:74/200	LOSS:1.062254
VAL	EPOCH:74/200	LOSS:0.832585
TRAIN	EPOCH:75/200	LOSS:1.059373
VAL	EPOCH:75/200	LOSS:0.841545
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:76/200	LOSS:1.063184
VAL	EPOCH:76/200	LOSS:0.829975
TRAIN	EPOCH:77/200	LOSS:1.066907
VAL	EPOCH:77/200	LOSS:0.854265
TRAIN	EPOCH:78/200	LOSS:1.065388
VAL	EPOCH:78/200	LOSS:0.844284
TRAIN	EPOCH:79/200	LOSS:1.059234
VAL	EPOCH:79/200	LOSS:0.837958
TRAIN	EPOCH:80/200	LOSS:1.055866
VAL	EPOCH:80/200	LOSS:0.843958
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:81/200	LOSS:1.056797
VAL	EPOCH:81/200	LOSS:0.841367
TRAIN	EPOCH:82/200	LOSS:1.057363
VAL	EPOCH:82/200	LOSS:0.837681
TRAIN	EPOCH:83/200	LOSS:1.062724
VAL	EPOCH:83/200	LOSS:0.835806
TRAIN	EPOCH:84/200	LOSS:1.053021
VAL	EPOCH:84/200	LOSS:0.825911
TRAIN	EPOCH:85/200	LOSS:1.059894
VAL	EPOCH:85/200	LOSS:0.848227
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:86/200	LOSS:1.056434
VAL	EPOCH:86/200	LOSS:0.818782
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:87/200	LOSS:1.056916
VAL	EPOCH:87/200	LOSS:0.828084
TRAIN	EPOCH:88/200	LOSS:1.057783
VAL	EPOCH:88/200	LOSS:0.830137
TRAIN	EPOCH:89/200	LOSS:1.056847
VAL	EPOCH:89/200	LOSS:0.835135
TRAIN	EPOCH:90/200	LOSS:1.054527
VAL	EPOCH:90/200	LOSS:0.827376
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:91/200	LOSS:1.058054
VAL	EPOCH:91/200	LOSS:0.8197
TRAIN	EPOCH:92/200	LOSS:1.056312
VAL	EPOCH:92/200	LOSS:0.832337
TRAIN	EPOCH:93/200	LOSS:1.06342
VAL	EPOCH:93/200	LOSS:0.852798
TRAIN	EPOCH:94/200	LOSS:1.065656
VAL	EPOCH:94/200	LOSS:0.832824
TRAIN	EPOCH:95/200	LOSS:1.054789
VAL	EPOCH:95/200	LOSS:0.834479
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:96/200	LOSS:1.056878
VAL	EPOCH:96/200	LOSS:0.844531
TRAIN	EPOCH:97/200	LOSS:1.055135
VAL	EPOCH:97/200	LOSS:0.833773
TRAIN	EPOCH:98/200	LOSS:1.057038
VAL	EPOCH:98/200	LOSS:0.835728
TRAIN	EPOCH:99/200	LOSS:1.05994
VAL	EPOCH:99/200	LOSS:0.836848
TRAIN	EPOCH:100/200	LOSS:1.06021
VAL	EPOCH:100/200	LOSS:0.83448
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:101/200	LOSS:1.062039
VAL	EPOCH:101/200	LOSS:0.821616
TRAIN	EPOCH:102/200	LOSS:1.058057
VAL	EPOCH:102/200	LOSS:0.853628
TRAIN	EPOCH:103/200	LOSS:1.06474
VAL	EPOCH:103/200	LOSS:0.825983
TRAIN	EPOCH:104/200	LOSS:1.060603
VAL	EPOCH:104/200	LOSS:0.84825
TRAIN	EPOCH:105/200	LOSS:1.073183
VAL	EPOCH:105/200	LOSS:0.848526
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:106/200	LOSS:1.058497
VAL	EPOCH:106/200	LOSS:0.824317
TRAIN	EPOCH:107/200	LOSS:1.058174
VAL	EPOCH:107/200	LOSS:0.824641
TRAIN	EPOCH:108/200	LOSS:1.053943
VAL	EPOCH:108/200	LOSS:0.82386
TRAIN	EPOCH:109/200	LOSS:1.059796
VAL	EPOCH:109/200	LOSS:0.83164
TRAIN	EPOCH:110/200	LOSS:1.063613
VAL	EPOCH:110/200	LOSS:0.830278
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:111/200	LOSS:1.056128
VAL	EPOCH:111/200	LOSS:0.828418
TRAIN	EPOCH:112/200	LOSS:1.053845
VAL	EPOCH:112/200	LOSS:0.832506
TRAIN	EPOCH:113/200	LOSS:1.056911
VAL	EPOCH:113/200	LOSS:0.82757
TRAIN	EPOCH:114/200	LOSS:1.056367
VAL	EPOCH:114/200	LOSS:0.824837
TRAIN	EPOCH:115/200	LOSS:1.058127
VAL	EPOCH:115/200	LOSS:0.837323
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:116/200	LOSS:1.058247
VAL	EPOCH:116/200	LOSS:0.845069
TRAIN	EPOCH:117/200	LOSS:1.057842
VAL	EPOCH:117/200	LOSS:0.842983
TRAIN	EPOCH:118/200	LOSS:1.056584
VAL	EPOCH:118/200	LOSS:0.829076
TRAIN	EPOCH:119/200	LOSS:1.054929
VAL	EPOCH:119/200	LOSS:0.836552
TRAIN	EPOCH:120/200	LOSS:1.057606
VAL	EPOCH:120/200	LOSS:0.851771
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:121/200	LOSS:1.056809
VAL	EPOCH:121/200	LOSS:0.841202
TRAIN	EPOCH:122/200	LOSS:1.055014
VAL	EPOCH:122/200	LOSS:0.825174
TRAIN	EPOCH:123/200	LOSS:1.056207
VAL	EPOCH:123/200	LOSS:0.834399
TRAIN	EPOCH:124/200	LOSS:1.056654
VAL	EPOCH:124/200	LOSS:0.826159
TRAIN	EPOCH:125/200	LOSS:1.05587
VAL	EPOCH:125/200	LOSS:0.83874
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:126/200	LOSS:1.052828
VAL	EPOCH:126/200	LOSS:0.834589
TRAIN	EPOCH:127/200	LOSS:1.050832
VAL	EPOCH:127/200	LOSS:0.828269
TRAIN	EPOCH:128/200	LOSS:1.058168
VAL	EPOCH:128/200	LOSS:0.829858
TRAIN	EPOCH:129/200	LOSS:1.055221
VAL	EPOCH:129/200	LOSS:0.829481
TRAIN	EPOCH:130/200	LOSS:1.05209
VAL	EPOCH:130/200	LOSS:0.821146
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:131/200	LOSS:1.052944
VAL	EPOCH:131/200	LOSS:0.823638
TRAIN	EPOCH:132/200	LOSS:1.051668
VAL	EPOCH:132/200	LOSS:0.827379
TRAIN	EPOCH:133/200	LOSS:1.053551
VAL	EPOCH:133/200	LOSS:0.828623
TRAIN	EPOCH:134/200	LOSS:1.056215
VAL	EPOCH:134/200	LOSS:0.826204
TRAIN	EPOCH:135/200	LOSS:1.055838
VAL	EPOCH:135/200	LOSS:0.829292
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:136/200	LOSS:1.055727
VAL	EPOCH:136/200	LOSS:0.836408
TRAIN	EPOCH:137/200	LOSS:1.057938
VAL	EPOCH:137/200	LOSS:0.83415
TRAIN	EPOCH:138/200	LOSS:1.054781
VAL	EPOCH:138/200	LOSS:0.829128
TRAIN	EPOCH:139/200	LOSS:1.058094
VAL	EPOCH:139/200	LOSS:0.84143
TRAIN	EPOCH:140/200	LOSS:1.055979
VAL	EPOCH:140/200	LOSS:0.81969
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:141/200	LOSS:1.054452
VAL	EPOCH:141/200	LOSS:0.815718
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:142/200	LOSS:1.054099
VAL	EPOCH:142/200	LOSS:0.829315
TRAIN	EPOCH:143/200	LOSS:1.058606
VAL	EPOCH:143/200	LOSS:0.829005
TRAIN	EPOCH:144/200	LOSS:1.055676
VAL	EPOCH:144/200	LOSS:0.822811
TRAIN	EPOCH:145/200	LOSS:1.05843
VAL	EPOCH:145/200	LOSS:0.844706
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:146/200	LOSS:1.054474
VAL	EPOCH:146/200	LOSS:0.822741
TRAIN	EPOCH:147/200	LOSS:1.05617
VAL	EPOCH:147/200	LOSS:0.831212
TRAIN	EPOCH:148/200	LOSS:1.059586
VAL	EPOCH:148/200	LOSS:0.827343
TRAIN	EPOCH:149/200	LOSS:1.058035
VAL	EPOCH:149/200	LOSS:0.825605
TRAIN	EPOCH:150/200	LOSS:1.057841
VAL	EPOCH:150/200	LOSS:0.839452
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:151/200	LOSS:1.05239
VAL	EPOCH:151/200	LOSS:0.830224
TRAIN	EPOCH:152/200	LOSS:1.050273
VAL	EPOCH:152/200	LOSS:0.830034
TRAIN	EPOCH:153/200	LOSS:1.062838
VAL	EPOCH:153/200	LOSS:0.832353
TRAIN	EPOCH:154/200	LOSS:1.059151
VAL	EPOCH:154/200	LOSS:0.84204
TRAIN	EPOCH:155/200	LOSS:1.053204
VAL	EPOCH:155/200	LOSS:0.823575
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:156/200	LOSS:1.053901
VAL	EPOCH:156/200	LOSS:0.823439
TRAIN	EPOCH:157/200	LOSS:1.056377
VAL	EPOCH:157/200	LOSS:0.840922
TRAIN	EPOCH:158/200	LOSS:1.050624
VAL	EPOCH:158/200	LOSS:0.819243
TRAIN	EPOCH:159/200	LOSS:1.053367
VAL	EPOCH:159/200	LOSS:0.823823
TRAIN	EPOCH:160/200	LOSS:1.051486
VAL	EPOCH:160/200	LOSS:0.825274
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:161/200	LOSS:1.049393
VAL	EPOCH:161/200	LOSS:0.84139
TRAIN	EPOCH:162/200	LOSS:1.060187
VAL	EPOCH:162/200	LOSS:0.829892
TRAIN	EPOCH:163/200	LOSS:1.052349
VAL	EPOCH:163/200	LOSS:0.832689
TRAIN	EPOCH:164/200	LOSS:1.054187
VAL	EPOCH:164/200	LOSS:0.822982
TRAIN	EPOCH:165/200	LOSS:1.057909
VAL	EPOCH:165/200	LOSS:0.835651
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:166/200	LOSS:1.055311
VAL	EPOCH:166/200	LOSS:0.825597
TRAIN	EPOCH:167/200	LOSS:1.071091
VAL	EPOCH:167/200	LOSS:0.825177
TRAIN	EPOCH:168/200	LOSS:1.058675
VAL	EPOCH:168/200	LOSS:0.834882
TRAIN	EPOCH:169/200	LOSS:1.057708
VAL	EPOCH:169/200	LOSS:0.832043
TRAIN	EPOCH:170/200	LOSS:1.052003
VAL	EPOCH:170/200	LOSS:0.821419
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:171/200	LOSS:1.051543
VAL	EPOCH:171/200	LOSS:0.840917
TRAIN	EPOCH:172/200	LOSS:1.054155
VAL	EPOCH:172/200	LOSS:0.83141
TRAIN	EPOCH:173/200	LOSS:1.052128
VAL	EPOCH:173/200	LOSS:0.827514
TRAIN	EPOCH:174/200	LOSS:1.054435
VAL	EPOCH:174/200	LOSS:0.824844
TRAIN	EPOCH:175/200	LOSS:1.049234
VAL	EPOCH:175/200	LOSS:0.828191
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:176/200	LOSS:1.054947
VAL	EPOCH:176/200	LOSS:0.817141
TRAIN	EPOCH:177/200	LOSS:1.061071
VAL	EPOCH:177/200	LOSS:0.83119
TRAIN	EPOCH:178/200	LOSS:1.054597
VAL	EPOCH:178/200	LOSS:0.827779
TRAIN	EPOCH:179/200	LOSS:1.055845
VAL	EPOCH:179/200	LOSS:0.834643
TRAIN	EPOCH:180/200	LOSS:1.054316
VAL	EPOCH:180/200	LOSS:0.83607
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:181/200	LOSS:1.050498
VAL	EPOCH:181/200	LOSS:0.838836
TRAIN	EPOCH:182/200	LOSS:1.05258
VAL	EPOCH:182/200	LOSS:0.820462
TRAIN	EPOCH:183/200	LOSS:1.055672
VAL	EPOCH:183/200	LOSS:0.835717
TRAIN	EPOCH:184/200	LOSS:1.057647
VAL	EPOCH:184/200	LOSS:0.835554
TRAIN	EPOCH:185/200	LOSS:1.054507
VAL	EPOCH:185/200	LOSS:0.832314
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:186/200	LOSS:1.05528
VAL	EPOCH:186/200	LOSS:0.832957
TRAIN	EPOCH:187/200	LOSS:1.051049
VAL	EPOCH:187/200	LOSS:0.823276
TRAIN	EPOCH:188/200	LOSS:1.054615
VAL	EPOCH:188/200	LOSS:0.843609
TRAIN	EPOCH:189/200	LOSS:1.060481
VAL	EPOCH:189/200	LOSS:0.83858
TRAIN	EPOCH:190/200	LOSS:1.052401
VAL	EPOCH:190/200	LOSS:0.832234
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:191/200	LOSS:1.051519
VAL	EPOCH:191/200	LOSS:0.833566
TRAIN	EPOCH:192/200	LOSS:1.049166
VAL	EPOCH:192/200	LOSS:0.813549
Lowest loss model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:193/200	LOSS:1.054481
VAL	EPOCH:193/200	LOSS:0.827213
TRAIN	EPOCH:194/200	LOSS:1.052618
VAL	EPOCH:194/200	LOSS:0.831365
TRAIN	EPOCH:195/200	LOSS:1.055746
VAL	EPOCH:195/200	LOSS:0.821579
Model saved at ./transf_l=2_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:196/200	LOSS:1.052606
VAL	EPOCH:196/200	LOSS:0.828211
TRAIN	EPOCH:197/200	LOSS:1.056066
VAL	EPOCH:197/200	LOSS:0.826051
TRAIN	EPOCH:198/200	LOSS:1.056573
VAL	EPOCH:198/200	LOSS:0.850002
TRAIN	EPOCH:199/200	LOSS:1.052824
VAL	EPOCH:199/200	LOSS:0.834773
Loading data...
Creating splits...
Creating model...
TransfModel(
  (embedding): Embedding(63, 64)
  (encoder_layer): TransformerEncoderLayer(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
    )
    (linear1): Linear(in_features=64, out_features=64, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
    (linear2): Linear(in_features=64, out_features=64, bias=True)
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-2): 3 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=64, bias=True)
        (dropout): Dropout(p=0.2, inplace=False)
        (linear2): Linear(in_features=64, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (positional_encoding): PositionalEncoding(
    (dropout): Dropout(p=0.2, inplace=False)
  )
  (prediction_layer): Linear(in_features=64, out_features=63, bias=True)
  (softmax): Softmax(dim=-1)
)
Using CUDA.
Training started.
TRAIN	EPOCH:0/200	LOSS:1.834427
VAL	EPOCH:0/200	LOSS:1.474253
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:1/200	LOSS:1.503028
VAL	EPOCH:1/200	LOSS:1.220379
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:2/200	LOSS:1.325625
VAL	EPOCH:2/200	LOSS:1.024049
TRAIN	EPOCH:3/200	LOSS:1.208758
VAL	EPOCH:3/200	LOSS:0.955341
TRAIN	EPOCH:4/200	LOSS:1.151443
VAL	EPOCH:4/200	LOSS:0.914438
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:5/200	LOSS:1.119398
VAL	EPOCH:5/200	LOSS:0.894405
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:6/200	LOSS:1.108568
VAL	EPOCH:6/200	LOSS:0.899225
TRAIN	EPOCH:7/200	LOSS:1.087256
VAL	EPOCH:7/200	LOSS:0.869701
TRAIN	EPOCH:8/200	LOSS:1.086132
VAL	EPOCH:8/200	LOSS:0.877889
TRAIN	EPOCH:9/200	LOSS:1.070591
VAL	EPOCH:9/200	LOSS:0.888514
TRAIN	EPOCH:10/200	LOSS:1.06429
VAL	EPOCH:10/200	LOSS:0.858201
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:11/200	LOSS:1.065956
VAL	EPOCH:11/200	LOSS:0.858779
TRAIN	EPOCH:12/200	LOSS:1.060917
VAL	EPOCH:12/200	LOSS:0.850159
TRAIN	EPOCH:13/200	LOSS:1.058342
VAL	EPOCH:13/200	LOSS:0.870691
TRAIN	EPOCH:14/200	LOSS:1.054859
VAL	EPOCH:14/200	LOSS:0.865098
TRAIN	EPOCH:15/200	LOSS:1.046214
VAL	EPOCH:15/200	LOSS:0.852686
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:16/200	LOSS:1.044873
VAL	EPOCH:16/200	LOSS:0.853765
TRAIN	EPOCH:17/200	LOSS:1.045108
VAL	EPOCH:17/200	LOSS:0.841857
TRAIN	EPOCH:18/200	LOSS:1.041878
VAL	EPOCH:18/200	LOSS:0.833942
TRAIN	EPOCH:19/200	LOSS:1.042132
VAL	EPOCH:19/200	LOSS:0.860714
TRAIN	EPOCH:20/200	LOSS:1.034114
VAL	EPOCH:20/200	LOSS:0.839677
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:21/200	LOSS:1.036203
VAL	EPOCH:21/200	LOSS:0.845464
TRAIN	EPOCH:22/200	LOSS:1.037482
VAL	EPOCH:22/200	LOSS:0.845389
TRAIN	EPOCH:23/200	LOSS:1.03946
VAL	EPOCH:23/200	LOSS:0.833794
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:24/200	LOSS:1.03235
VAL	EPOCH:24/200	LOSS:0.833935
TRAIN	EPOCH:25/200	LOSS:1.026761
VAL	EPOCH:25/200	LOSS:0.825601
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:26/200	LOSS:1.025195
VAL	EPOCH:26/200	LOSS:0.839198
TRAIN	EPOCH:27/200	LOSS:1.025248
VAL	EPOCH:27/200	LOSS:0.850203
TRAIN	EPOCH:28/200	LOSS:1.027014
VAL	EPOCH:28/200	LOSS:0.835926
TRAIN	EPOCH:29/200	LOSS:1.03273
VAL	EPOCH:29/200	LOSS:0.84963
TRAIN	EPOCH:30/200	LOSS:1.024247
VAL	EPOCH:30/200	LOSS:0.840699
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:31/200	LOSS:1.018366
VAL	EPOCH:31/200	LOSS:0.818671
TRAIN	EPOCH:32/200	LOSS:1.026393
VAL	EPOCH:32/200	LOSS:0.836988
TRAIN	EPOCH:33/200	LOSS:1.019265
VAL	EPOCH:33/200	LOSS:0.818672
TRAIN	EPOCH:34/200	LOSS:1.026228
VAL	EPOCH:34/200	LOSS:0.827283
TRAIN	EPOCH:35/200	LOSS:1.021392
VAL	EPOCH:35/200	LOSS:0.826471
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:36/200	LOSS:1.014559
VAL	EPOCH:36/200	LOSS:0.838924
TRAIN	EPOCH:37/200	LOSS:1.025192
VAL	EPOCH:37/200	LOSS:0.819485
TRAIN	EPOCH:38/200	LOSS:1.02137
VAL	EPOCH:38/200	LOSS:0.831978
TRAIN	EPOCH:39/200	LOSS:1.020253
VAL	EPOCH:39/200	LOSS:0.835704
TRAIN	EPOCH:40/200	LOSS:1.02515
VAL	EPOCH:40/200	LOSS:0.810381
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:41/200	LOSS:1.015597
VAL	EPOCH:41/200	LOSS:0.834748
TRAIN	EPOCH:42/200	LOSS:1.034093
VAL	EPOCH:42/200	LOSS:0.859573
TRAIN	EPOCH:43/200	LOSS:1.028839
VAL	EPOCH:43/200	LOSS:0.81883
TRAIN	EPOCH:44/200	LOSS:1.017753
VAL	EPOCH:44/200	LOSS:0.837365
TRAIN	EPOCH:45/200	LOSS:1.011884
VAL	EPOCH:45/200	LOSS:0.833096
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:46/200	LOSS:1.011848
VAL	EPOCH:46/200	LOSS:0.822844
TRAIN	EPOCH:47/200	LOSS:1.020816
VAL	EPOCH:47/200	LOSS:0.845332
TRAIN	EPOCH:48/200	LOSS:1.019977
VAL	EPOCH:48/200	LOSS:0.83518
TRAIN	EPOCH:49/200	LOSS:1.011289
VAL	EPOCH:49/200	LOSS:0.823928
TRAIN	EPOCH:50/200	LOSS:1.016997
VAL	EPOCH:50/200	LOSS:0.828026
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:51/200	LOSS:1.02506
VAL	EPOCH:51/200	LOSS:0.836027
TRAIN	EPOCH:52/200	LOSS:1.01033
VAL	EPOCH:52/200	LOSS:0.820233
TRAIN	EPOCH:53/200	LOSS:1.012671
VAL	EPOCH:53/200	LOSS:0.820891
TRAIN	EPOCH:54/200	LOSS:1.012782
VAL	EPOCH:54/200	LOSS:0.828677
TRAIN	EPOCH:55/200	LOSS:1.017872
VAL	EPOCH:55/200	LOSS:0.814617
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:56/200	LOSS:1.013512
VAL	EPOCH:56/200	LOSS:0.805512
TRAIN	EPOCH:57/200	LOSS:1.019131
VAL	EPOCH:57/200	LOSS:0.835752
TRAIN	EPOCH:58/200	LOSS:1.044915
VAL	EPOCH:58/200	LOSS:0.849953
TRAIN	EPOCH:59/200	LOSS:1.026937
VAL	EPOCH:59/200	LOSS:0.829165
TRAIN	EPOCH:60/200	LOSS:1.018036
VAL	EPOCH:60/200	LOSS:0.831363
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:61/200	LOSS:1.024041
VAL	EPOCH:61/200	LOSS:0.830442
TRAIN	EPOCH:62/200	LOSS:1.014701
VAL	EPOCH:62/200	LOSS:0.811088
TRAIN	EPOCH:63/200	LOSS:1.016485
VAL	EPOCH:63/200	LOSS:0.840934
TRAIN	EPOCH:64/200	LOSS:1.019321
VAL	EPOCH:64/200	LOSS:0.813362
TRAIN	EPOCH:65/200	LOSS:1.022292
VAL	EPOCH:65/200	LOSS:0.817
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:66/200	LOSS:1.020167
VAL	EPOCH:66/200	LOSS:0.828549
TRAIN	EPOCH:67/200	LOSS:1.015859
VAL	EPOCH:67/200	LOSS:0.817322
TRAIN	EPOCH:68/200	LOSS:1.013768
VAL	EPOCH:68/200	LOSS:0.816402
TRAIN	EPOCH:69/200	LOSS:1.019172
VAL	EPOCH:69/200	LOSS:0.819275
TRAIN	EPOCH:70/200	LOSS:1.010904
VAL	EPOCH:70/200	LOSS:0.826553
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:71/200	LOSS:1.015318
VAL	EPOCH:71/200	LOSS:0.817053
TRAIN	EPOCH:72/200	LOSS:1.012555
VAL	EPOCH:72/200	LOSS:0.818384
TRAIN	EPOCH:73/200	LOSS:1.017202
VAL	EPOCH:73/200	LOSS:0.837005
TRAIN	EPOCH:74/200	LOSS:1.02937
VAL	EPOCH:74/200	LOSS:0.833636
TRAIN	EPOCH:75/200	LOSS:1.021155
VAL	EPOCH:75/200	LOSS:0.831238
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:76/200	LOSS:1.013203
VAL	EPOCH:76/200	LOSS:0.835761
TRAIN	EPOCH:77/200	LOSS:1.01471
VAL	EPOCH:77/200	LOSS:0.81798
TRAIN	EPOCH:78/200	LOSS:1.015899
VAL	EPOCH:78/200	LOSS:0.811348
TRAIN	EPOCH:79/200	LOSS:1.016027
VAL	EPOCH:79/200	LOSS:0.812463
TRAIN	EPOCH:80/200	LOSS:1.010254
VAL	EPOCH:80/200	LOSS:0.840096
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:81/200	LOSS:1.015508
VAL	EPOCH:81/200	LOSS:0.81245
TRAIN	EPOCH:82/200	LOSS:1.011699
VAL	EPOCH:82/200	LOSS:0.812426
TRAIN	EPOCH:83/200	LOSS:1.007133
VAL	EPOCH:83/200	LOSS:0.812318
TRAIN	EPOCH:84/200	LOSS:1.021598
VAL	EPOCH:84/200	LOSS:0.834241
TRAIN	EPOCH:85/200	LOSS:1.012829
VAL	EPOCH:85/200	LOSS:0.818688
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:86/200	LOSS:1.02488
VAL	EPOCH:86/200	LOSS:0.825567
TRAIN	EPOCH:87/200	LOSS:1.011222
VAL	EPOCH:87/200	LOSS:0.808527
TRAIN	EPOCH:88/200	LOSS:1.01042
VAL	EPOCH:88/200	LOSS:0.819215
TRAIN	EPOCH:89/200	LOSS:1.009558
VAL	EPOCH:89/200	LOSS:0.80784
TRAIN	EPOCH:90/200	LOSS:1.010161
VAL	EPOCH:90/200	LOSS:0.815214
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:91/200	LOSS:1.011783
VAL	EPOCH:91/200	LOSS:0.811708
TRAIN	EPOCH:92/200	LOSS:1.013371
VAL	EPOCH:92/200	LOSS:0.830563
TRAIN	EPOCH:93/200	LOSS:1.03444
VAL	EPOCH:93/200	LOSS:0.825503
TRAIN	EPOCH:94/200	LOSS:1.017467
VAL	EPOCH:94/200	LOSS:0.801705
TRAIN	EPOCH:95/200	LOSS:1.005809
VAL	EPOCH:95/200	LOSS:0.806379
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:96/200	LOSS:1.009656
VAL	EPOCH:96/200	LOSS:0.82524
TRAIN	EPOCH:97/200	LOSS:1.010232
VAL	EPOCH:97/200	LOSS:0.82256
TRAIN	EPOCH:98/200	LOSS:1.012343
VAL	EPOCH:98/200	LOSS:0.817209
TRAIN	EPOCH:99/200	LOSS:1.011165
VAL	EPOCH:99/200	LOSS:0.811948
TRAIN	EPOCH:100/200	LOSS:1.010743
VAL	EPOCH:100/200	LOSS:0.814492
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:101/200	LOSS:1.011899
VAL	EPOCH:101/200	LOSS:0.840204
TRAIN	EPOCH:102/200	LOSS:1.04438
VAL	EPOCH:102/200	LOSS:0.820718
TRAIN	EPOCH:103/200	LOSS:1.008376
VAL	EPOCH:103/200	LOSS:0.807374
TRAIN	EPOCH:104/200	LOSS:1.016909
VAL	EPOCH:104/200	LOSS:0.836645
TRAIN	EPOCH:105/200	LOSS:1.008894
VAL	EPOCH:105/200	LOSS:0.80667
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:106/200	LOSS:1.006563
VAL	EPOCH:106/200	LOSS:0.808389
TRAIN	EPOCH:107/200	LOSS:1.010883
VAL	EPOCH:107/200	LOSS:0.81298
TRAIN	EPOCH:108/200	LOSS:1.009402
VAL	EPOCH:108/200	LOSS:0.820594
TRAIN	EPOCH:109/200	LOSS:1.043219
VAL	EPOCH:109/200	LOSS:0.820635
TRAIN	EPOCH:110/200	LOSS:1.01502
VAL	EPOCH:110/200	LOSS:0.848974
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
Patience reached. Early stopping.
Loading data...
Creating splits...
Creating model...
TransfModel(
  (embedding): Embedding(63, 64)
  (encoder_layer): TransformerEncoderLayer(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
    )
    (linear1): Linear(in_features=64, out_features=64, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
    (linear2): Linear(in_features=64, out_features=64, bias=True)
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-2): 3 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=64, bias=True)
        (dropout): Dropout(p=0.2, inplace=False)
        (linear2): Linear(in_features=64, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (positional_encoding): PositionalEncoding(
    (dropout): Dropout(p=0.2, inplace=False)
  )
  (prediction_layer): Linear(in_features=64, out_features=63, bias=True)
  (softmax): Softmax(dim=-1)
)
Using CUDA.
Training started.
TRAIN	EPOCH:0/200	LOSS:1.834427
VAL	EPOCH:0/200	LOSS:1.474253
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:1/200	LOSS:1.503028
VAL	EPOCH:1/200	LOSS:1.220379
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:2/200	LOSS:1.325625
VAL	EPOCH:2/200	LOSS:1.024049
TRAIN	EPOCH:3/200	LOSS:1.208758
VAL	EPOCH:3/200	LOSS:0.955341
TRAIN	EPOCH:4/200	LOSS:1.151443
VAL	EPOCH:4/200	LOSS:0.914438
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:5/200	LOSS:1.119398
VAL	EPOCH:5/200	LOSS:0.894405
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:6/200	LOSS:1.108568
VAL	EPOCH:6/200	LOSS:0.899225
TRAIN	EPOCH:7/200	LOSS:1.087256
VAL	EPOCH:7/200	LOSS:0.869701
TRAIN	EPOCH:8/200	LOSS:1.086132
VAL	EPOCH:8/200	LOSS:0.877889
TRAIN	EPOCH:9/200	LOSS:1.070591
VAL	EPOCH:9/200	LOSS:0.888514
TRAIN	EPOCH:10/200	LOSS:1.06429
VAL	EPOCH:10/200	LOSS:0.858201
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:11/200	LOSS:1.065956
VAL	EPOCH:11/200	LOSS:0.858779
TRAIN	EPOCH:12/200	LOSS:1.060917
VAL	EPOCH:12/200	LOSS:0.850159
TRAIN	EPOCH:13/200	LOSS:1.058342
VAL	EPOCH:13/200	LOSS:0.870691
TRAIN	EPOCH:14/200	LOSS:1.054859
VAL	EPOCH:14/200	LOSS:0.865098
TRAIN	EPOCH:15/200	LOSS:1.046214
VAL	EPOCH:15/200	LOSS:0.852686
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:16/200	LOSS:1.044873
VAL	EPOCH:16/200	LOSS:0.853765
TRAIN	EPOCH:17/200	LOSS:1.045108
VAL	EPOCH:17/200	LOSS:0.841857
TRAIN	EPOCH:18/200	LOSS:1.041878
VAL	EPOCH:18/200	LOSS:0.833942
TRAIN	EPOCH:19/200	LOSS:1.042132
VAL	EPOCH:19/200	LOSS:0.860714
TRAIN	EPOCH:20/200	LOSS:1.034114
VAL	EPOCH:20/200	LOSS:0.839677
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:21/200	LOSS:1.036203
VAL	EPOCH:21/200	LOSS:0.845464
TRAIN	EPOCH:22/200	LOSS:1.037482
VAL	EPOCH:22/200	LOSS:0.845389
TRAIN	EPOCH:23/200	LOSS:1.03946
VAL	EPOCH:23/200	LOSS:0.833795
TRAIN	EPOCH:24/200	LOSS:1.03235
VAL	EPOCH:24/200	LOSS:0.833935
TRAIN	EPOCH:25/200	LOSS:1.026761
VAL	EPOCH:25/200	LOSS:0.825601
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:26/200	LOSS:1.025195
VAL	EPOCH:26/200	LOSS:0.839198
TRAIN	EPOCH:27/200	LOSS:1.025248
VAL	EPOCH:27/200	LOSS:0.850203
TRAIN	EPOCH:28/200	LOSS:1.027014
VAL	EPOCH:28/200	LOSS:0.835926
TRAIN	EPOCH:29/200	LOSS:1.03273
VAL	EPOCH:29/200	LOSS:0.84963
TRAIN	EPOCH:30/200	LOSS:1.024247
VAL	EPOCH:30/200	LOSS:0.840699
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:31/200	LOSS:1.018366
VAL	EPOCH:31/200	LOSS:0.818671
TRAIN	EPOCH:32/200	LOSS:1.026393
VAL	EPOCH:32/200	LOSS:0.836988
TRAIN	EPOCH:33/200	LOSS:1.019265
VAL	EPOCH:33/200	LOSS:0.818672
TRAIN	EPOCH:34/200	LOSS:1.026228
VAL	EPOCH:34/200	LOSS:0.827283
TRAIN	EPOCH:35/200	LOSS:1.021392
VAL	EPOCH:35/200	LOSS:0.826471
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:36/200	LOSS:1.014559
VAL	EPOCH:36/200	LOSS:0.838924
TRAIN	EPOCH:37/200	LOSS:1.025192
VAL	EPOCH:37/200	LOSS:0.819485
TRAIN	EPOCH:38/200	LOSS:1.02137
VAL	EPOCH:38/200	LOSS:0.831978
TRAIN	EPOCH:39/200	LOSS:1.020253
VAL	EPOCH:39/200	LOSS:0.835704
TRAIN	EPOCH:40/200	LOSS:1.02515
VAL	EPOCH:40/200	LOSS:0.810381
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:41/200	LOSS:1.015597
VAL	EPOCH:41/200	LOSS:0.834748
TRAIN	EPOCH:42/200	LOSS:1.034093
VAL	EPOCH:42/200	LOSS:0.859573
TRAIN	EPOCH:43/200	LOSS:1.028839
VAL	EPOCH:43/200	LOSS:0.81883
TRAIN	EPOCH:44/200	LOSS:1.017753
VAL	EPOCH:44/200	LOSS:0.837365
TRAIN	EPOCH:45/200	LOSS:1.011884
VAL	EPOCH:45/200	LOSS:0.833096
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:46/200	LOSS:1.011848
VAL	EPOCH:46/200	LOSS:0.822844
TRAIN	EPOCH:47/200	LOSS:1.020816
VAL	EPOCH:47/200	LOSS:0.845332
TRAIN	EPOCH:48/200	LOSS:1.019977
VAL	EPOCH:48/200	LOSS:0.83518
TRAIN	EPOCH:49/200	LOSS:1.011289
VAL	EPOCH:49/200	LOSS:0.823928
TRAIN	EPOCH:50/200	LOSS:1.016997
VAL	EPOCH:50/200	LOSS:0.828026
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:51/200	LOSS:1.02506
VAL	EPOCH:51/200	LOSS:0.836027
TRAIN	EPOCH:52/200	LOSS:1.01033
VAL	EPOCH:52/200	LOSS:0.820233
TRAIN	EPOCH:53/200	LOSS:1.012671
VAL	EPOCH:53/200	LOSS:0.820891
TRAIN	EPOCH:54/200	LOSS:1.012782
VAL	EPOCH:54/200	LOSS:0.828677
TRAIN	EPOCH:55/200	LOSS:1.017872
VAL	EPOCH:55/200	LOSS:0.814617
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:56/200	LOSS:1.013512
VAL	EPOCH:56/200	LOSS:0.805512
TRAIN	EPOCH:57/200	LOSS:1.019131
VAL	EPOCH:57/200	LOSS:0.835752
TRAIN	EPOCH:58/200	LOSS:1.044915
VAL	EPOCH:58/200	LOSS:0.849953
TRAIN	EPOCH:59/200	LOSS:1.026937
VAL	EPOCH:59/200	LOSS:0.829165
TRAIN	EPOCH:60/200	LOSS:1.018036
VAL	EPOCH:60/200	LOSS:0.831364
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:61/200	LOSS:1.024041
VAL	EPOCH:61/200	LOSS:0.830442
TRAIN	EPOCH:62/200	LOSS:1.014701
VAL	EPOCH:62/200	LOSS:0.811088
TRAIN	EPOCH:63/200	LOSS:1.016485
VAL	EPOCH:63/200	LOSS:0.840934
TRAIN	EPOCH:64/200	LOSS:1.019321
VAL	EPOCH:64/200	LOSS:0.813362
TRAIN	EPOCH:65/200	LOSS:1.022292
VAL	EPOCH:65/200	LOSS:0.817
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:66/200	LOSS:1.020167
VAL	EPOCH:66/200	LOSS:0.828549
TRAIN	EPOCH:67/200	LOSS:1.015858
VAL	EPOCH:67/200	LOSS:0.817322
TRAIN	EPOCH:68/200	LOSS:1.013768
VAL	EPOCH:68/200	LOSS:0.816402
TRAIN	EPOCH:69/200	LOSS:1.019172
VAL	EPOCH:69/200	LOSS:0.819275
TRAIN	EPOCH:70/200	LOSS:1.010904
VAL	EPOCH:70/200	LOSS:0.826552
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:71/200	LOSS:1.015318
VAL	EPOCH:71/200	LOSS:0.817053
TRAIN	EPOCH:72/200	LOSS:1.012555
VAL	EPOCH:72/200	LOSS:0.818384
TRAIN	EPOCH:73/200	LOSS:1.017202
VAL	EPOCH:73/200	LOSS:0.837005
TRAIN	EPOCH:74/200	LOSS:1.02937
VAL	EPOCH:74/200	LOSS:0.833636
TRAIN	EPOCH:75/200	LOSS:1.021155
VAL	EPOCH:75/200	LOSS:0.831238
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:76/200	LOSS:1.013203
VAL	EPOCH:76/200	LOSS:0.835761
TRAIN	EPOCH:77/200	LOSS:1.01471
VAL	EPOCH:77/200	LOSS:0.81798
TRAIN	EPOCH:78/200	LOSS:1.015899
VAL	EPOCH:78/200	LOSS:0.811348
TRAIN	EPOCH:79/200	LOSS:1.016027
VAL	EPOCH:79/200	LOSS:0.812463
TRAIN	EPOCH:80/200	LOSS:1.010254
VAL	EPOCH:80/200	LOSS:0.840096
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:81/200	LOSS:1.015508
VAL	EPOCH:81/200	LOSS:0.81245
TRAIN	EPOCH:82/200	LOSS:1.011699
VAL	EPOCH:82/200	LOSS:0.812426
TRAIN	EPOCH:83/200	LOSS:1.007133
VAL	EPOCH:83/200	LOSS:0.812318
TRAIN	EPOCH:84/200	LOSS:1.021598
VAL	EPOCH:84/200	LOSS:0.834241
TRAIN	EPOCH:85/200	LOSS:1.012829
VAL	EPOCH:85/200	LOSS:0.818688
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:86/200	LOSS:1.02488
VAL	EPOCH:86/200	LOSS:0.825567
TRAIN	EPOCH:87/200	LOSS:1.011222
VAL	EPOCH:87/200	LOSS:0.808527
TRAIN	EPOCH:88/200	LOSS:1.01042
VAL	EPOCH:88/200	LOSS:0.819215
TRAIN	EPOCH:89/200	LOSS:1.009558
VAL	EPOCH:89/200	LOSS:0.80784
TRAIN	EPOCH:90/200	LOSS:1.010161
VAL	EPOCH:90/200	LOSS:0.815214
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:91/200	LOSS:1.011783
VAL	EPOCH:91/200	LOSS:0.811708
TRAIN	EPOCH:92/200	LOSS:1.013371
VAL	EPOCH:92/200	LOSS:0.830563
TRAIN	EPOCH:93/200	LOSS:1.03444
VAL	EPOCH:93/200	LOSS:0.825503
TRAIN	EPOCH:94/200	LOSS:1.017467
VAL	EPOCH:94/200	LOSS:0.801705
TRAIN	EPOCH:95/200	LOSS:1.005809
VAL	EPOCH:95/200	LOSS:0.806379
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:96/200	LOSS:1.009656
VAL	EPOCH:96/200	LOSS:0.82524
TRAIN	EPOCH:97/200	LOSS:1.010232
VAL	EPOCH:97/200	LOSS:0.82256
TRAIN	EPOCH:98/200	LOSS:1.012343
VAL	EPOCH:98/200	LOSS:0.817209
TRAIN	EPOCH:99/200	LOSS:1.011165
VAL	EPOCH:99/200	LOSS:0.811948
TRAIN	EPOCH:100/200	LOSS:1.010743
VAL	EPOCH:100/200	LOSS:0.814492
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:101/200	LOSS:1.011899
VAL	EPOCH:101/200	LOSS:0.840204
TRAIN	EPOCH:102/200	LOSS:1.04438
VAL	EPOCH:102/200	LOSS:0.820718
TRAIN	EPOCH:103/200	LOSS:1.008376
VAL	EPOCH:103/200	LOSS:0.807374
TRAIN	EPOCH:104/200	LOSS:1.016909
VAL	EPOCH:104/200	LOSS:0.836645
TRAIN	EPOCH:105/200	LOSS:1.008894
VAL	EPOCH:105/200	LOSS:0.80667
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:106/200	LOSS:1.006563
VAL	EPOCH:106/200	LOSS:0.808389
TRAIN	EPOCH:107/200	LOSS:1.010883
VAL	EPOCH:107/200	LOSS:0.81298
TRAIN	EPOCH:108/200	LOSS:1.009402
VAL	EPOCH:108/200	LOSS:0.820594
TRAIN	EPOCH:109/200	LOSS:1.043219
VAL	EPOCH:109/200	LOSS:0.820635
TRAIN	EPOCH:110/200	LOSS:1.01502
VAL	EPOCH:110/200	LOSS:0.848974
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.01_bs=16_ah=4/checkpoint.pytorch
Patience reached. Early stopping.
Loading data...
Creating splits...
Creating model...
TransfModel(
  (embedding): Embedding(63, 64)
  (encoder_layer): TransformerEncoderLayer(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
    )
    (linear1): Linear(in_features=64, out_features=64, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
    (linear2): Linear(in_features=64, out_features=64, bias=True)
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-2): 3 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=64, bias=True)
        (dropout): Dropout(p=0.2, inplace=False)
        (linear2): Linear(in_features=64, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (positional_encoding): PositionalEncoding(
    (dropout): Dropout(p=0.2, inplace=False)
  )
  (prediction_layer): Linear(in_features=64, out_features=63, bias=True)
  (softmax): Softmax(dim=-1)
)
Using CUDA.
Training started.
TRAIN	EPOCH:0/200	LOSS:2.203424
VAL	EPOCH:0/200	LOSS:1.737923
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:1/200	LOSS:1.732693
VAL	EPOCH:1/200	LOSS:1.547061
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:2/200	LOSS:1.602253
VAL	EPOCH:2/200	LOSS:1.407691
TRAIN	EPOCH:3/200	LOSS:1.50435
VAL	EPOCH:3/200	LOSS:1.29132
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:4/200	LOSS:1.431587
VAL	EPOCH:4/200	LOSS:1.198328
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:5/200	LOSS:1.371607
VAL	EPOCH:5/200	LOSS:1.113113
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:6/200	LOSS:1.324203
VAL	EPOCH:6/200	LOSS:1.063272
TRAIN	EPOCH:7/200	LOSS:1.278931
VAL	EPOCH:7/200	LOSS:1.013373
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:8/200	LOSS:1.24283
VAL	EPOCH:8/200	LOSS:0.984619
TRAIN	EPOCH:9/200	LOSS:1.213549
VAL	EPOCH:9/200	LOSS:0.950581
TRAIN	EPOCH:10/200	LOSS:1.186648
VAL	EPOCH:10/200	LOSS:0.926746
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:11/200	LOSS:1.164444
VAL	EPOCH:11/200	LOSS:0.901904
TRAIN	EPOCH:12/200	LOSS:1.141185
VAL	EPOCH:12/200	LOSS:0.883111
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:13/200	LOSS:1.125098
VAL	EPOCH:13/200	LOSS:0.871575
TRAIN	EPOCH:14/200	LOSS:1.108228
VAL	EPOCH:14/200	LOSS:0.86608
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:15/200	LOSS:1.096093
VAL	EPOCH:15/200	LOSS:0.852202
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:16/200	LOSS:1.080026
VAL	EPOCH:16/200	LOSS:0.838862
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:17/200	LOSS:1.072185
VAL	EPOCH:17/200	LOSS:0.828444
TRAIN	EPOCH:18/200	LOSS:1.059515
VAL	EPOCH:18/200	LOSS:0.831382
TRAIN	EPOCH:19/200	LOSS:1.051492
VAL	EPOCH:19/200	LOSS:0.826048
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:20/200	LOSS:1.03958
VAL	EPOCH:20/200	LOSS:0.812255
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:21/200	LOSS:1.03224
VAL	EPOCH:21/200	LOSS:0.809774
TRAIN	EPOCH:22/200	LOSS:1.025573
VAL	EPOCH:22/200	LOSS:0.797024
TRAIN	EPOCH:23/200	LOSS:1.018151
VAL	EPOCH:23/200	LOSS:0.790623
TRAIN	EPOCH:24/200	LOSS:1.012591
VAL	EPOCH:24/200	LOSS:0.785608
TRAIN	EPOCH:25/200	LOSS:1.004965
VAL	EPOCH:25/200	LOSS:0.788044
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:26/200	LOSS:1.000272
VAL	EPOCH:26/200	LOSS:0.783414
TRAIN	EPOCH:27/200	LOSS:0.991826
VAL	EPOCH:27/200	LOSS:0.774161
TRAIN	EPOCH:28/200	LOSS:0.98884
VAL	EPOCH:28/200	LOSS:0.77456
TRAIN	EPOCH:29/200	LOSS:0.983132
VAL	EPOCH:29/200	LOSS:0.779897
TRAIN	EPOCH:30/200	LOSS:0.980321
VAL	EPOCH:30/200	LOSS:0.773386
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:31/200	LOSS:0.973936
VAL	EPOCH:31/200	LOSS:0.770397
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:32/200	LOSS:0.969961
VAL	EPOCH:32/200	LOSS:0.760272
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:33/200	LOSS:0.966089
VAL	EPOCH:33/200	LOSS:0.760839
TRAIN	EPOCH:34/200	LOSS:0.962245
VAL	EPOCH:34/200	LOSS:0.752825
TRAIN	EPOCH:35/200	LOSS:0.957574
VAL	EPOCH:35/200	LOSS:0.753415
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:36/200	LOSS:0.953364
VAL	EPOCH:36/200	LOSS:0.752767
TRAIN	EPOCH:37/200	LOSS:0.951013
VAL	EPOCH:37/200	LOSS:0.752339
TRAIN	EPOCH:38/200	LOSS:0.949692
VAL	EPOCH:38/200	LOSS:0.749656
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:39/200	LOSS:0.942704
VAL	EPOCH:39/200	LOSS:0.740595
TRAIN	EPOCH:40/200	LOSS:0.94038
VAL	EPOCH:40/200	LOSS:0.744224
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:41/200	LOSS:0.938772
VAL	EPOCH:41/200	LOSS:0.74056
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:42/200	LOSS:0.935601
VAL	EPOCH:42/200	LOSS:0.739171
TRAIN	EPOCH:43/200	LOSS:0.932259
VAL	EPOCH:43/200	LOSS:0.741127
TRAIN	EPOCH:44/200	LOSS:0.930906
VAL	EPOCH:44/200	LOSS:0.737567
TRAIN	EPOCH:45/200	LOSS:0.927934
VAL	EPOCH:45/200	LOSS:0.738303
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:46/200	LOSS:0.924895
VAL	EPOCH:46/200	LOSS:0.72748
TRAIN	EPOCH:47/200	LOSS:0.922849
VAL	EPOCH:47/200	LOSS:0.7334
TRAIN	EPOCH:48/200	LOSS:0.92276
VAL	EPOCH:48/200	LOSS:0.727073
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:49/200	LOSS:0.920184
VAL	EPOCH:49/200	LOSS:0.725292
TRAIN	EPOCH:50/200	LOSS:0.918543
VAL	EPOCH:50/200	LOSS:0.726518
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:51/200	LOSS:0.915382
VAL	EPOCH:51/200	LOSS:0.721073
TRAIN	EPOCH:52/200	LOSS:0.9131
VAL	EPOCH:52/200	LOSS:0.716329
TRAIN	EPOCH:53/200	LOSS:0.911368
VAL	EPOCH:53/200	LOSS:0.720945
TRAIN	EPOCH:54/200	LOSS:0.912099
VAL	EPOCH:54/200	LOSS:0.725478
TRAIN	EPOCH:55/200	LOSS:0.909118
VAL	EPOCH:55/200	LOSS:0.722719
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:56/200	LOSS:0.906875
VAL	EPOCH:56/200	LOSS:0.717814
TRAIN	EPOCH:57/200	LOSS:0.906447
VAL	EPOCH:57/200	LOSS:0.718537
TRAIN	EPOCH:58/200	LOSS:0.902918
VAL	EPOCH:58/200	LOSS:0.708869
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:59/200	LOSS:0.903069
VAL	EPOCH:59/200	LOSS:0.711749
TRAIN	EPOCH:60/200	LOSS:0.899917
VAL	EPOCH:60/200	LOSS:0.708717
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:61/200	LOSS:0.899136
VAL	EPOCH:61/200	LOSS:0.709978
TRAIN	EPOCH:62/200	LOSS:0.898575
VAL	EPOCH:62/200	LOSS:0.708282
TRAIN	EPOCH:63/200	LOSS:0.897279
VAL	EPOCH:63/200	LOSS:0.704158
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:64/200	LOSS:0.895352
VAL	EPOCH:64/200	LOSS:0.70734
TRAIN	EPOCH:65/200	LOSS:0.896125
VAL	EPOCH:65/200	LOSS:0.706903
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:66/200	LOSS:0.893413
VAL	EPOCH:66/200	LOSS:0.707827
TRAIN	EPOCH:67/200	LOSS:0.891468
VAL	EPOCH:67/200	LOSS:0.708457
TRAIN	EPOCH:68/200	LOSS:0.891486
VAL	EPOCH:68/200	LOSS:0.701392
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:69/200	LOSS:0.890212
VAL	EPOCH:69/200	LOSS:0.705699
TRAIN	EPOCH:70/200	LOSS:0.886664
VAL	EPOCH:70/200	LOSS:0.70485
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:71/200	LOSS:0.888455
VAL	EPOCH:71/200	LOSS:0.698061
TRAIN	EPOCH:72/200	LOSS:0.886813
VAL	EPOCH:72/200	LOSS:0.702359
TRAIN	EPOCH:73/200	LOSS:0.887943
VAL	EPOCH:73/200	LOSS:0.7012
TRAIN	EPOCH:74/200	LOSS:0.885914
VAL	EPOCH:74/200	LOSS:0.700139
TRAIN	EPOCH:75/200	LOSS:0.884929
VAL	EPOCH:75/200	LOSS:0.701911
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:76/200	LOSS:0.883687
VAL	EPOCH:76/200	LOSS:0.700781
TRAIN	EPOCH:77/200	LOSS:0.882378
VAL	EPOCH:77/200	LOSS:0.69383
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:78/200	LOSS:0.879662
VAL	EPOCH:78/200	LOSS:0.692038
TRAIN	EPOCH:79/200	LOSS:0.87854
VAL	EPOCH:79/200	LOSS:0.698169
TRAIN	EPOCH:80/200	LOSS:0.879948
VAL	EPOCH:80/200	LOSS:0.697047
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:81/200	LOSS:0.878184
VAL	EPOCH:81/200	LOSS:0.699143
TRAIN	EPOCH:82/200	LOSS:0.878093
VAL	EPOCH:82/200	LOSS:0.69608
TRAIN	EPOCH:83/200	LOSS:0.877562
VAL	EPOCH:83/200	LOSS:0.691372
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:84/200	LOSS:0.875985
VAL	EPOCH:84/200	LOSS:0.688081
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:85/200	LOSS:0.874096
VAL	EPOCH:85/200	LOSS:0.703971
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:86/200	LOSS:0.873277
VAL	EPOCH:86/200	LOSS:0.686636
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:87/200	LOSS:0.872938
VAL	EPOCH:87/200	LOSS:0.685862
TRAIN	EPOCH:88/200	LOSS:0.871893
VAL	EPOCH:88/200	LOSS:0.692979
TRAIN	EPOCH:89/200	LOSS:0.873552
VAL	EPOCH:89/200	LOSS:0.698775
TRAIN	EPOCH:90/200	LOSS:0.870407
VAL	EPOCH:90/200	LOSS:0.686989
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:91/200	LOSS:0.870356
VAL	EPOCH:91/200	LOSS:0.684874
TRAIN	EPOCH:92/200	LOSS:0.870929
VAL	EPOCH:92/200	LOSS:0.692258
TRAIN	EPOCH:93/200	LOSS:0.868746
VAL	EPOCH:93/200	LOSS:0.691884
TRAIN	EPOCH:94/200	LOSS:0.867891
VAL	EPOCH:94/200	LOSS:0.681314
TRAIN	EPOCH:95/200	LOSS:0.866677
VAL	EPOCH:95/200	LOSS:0.678647
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:96/200	LOSS:0.867463
VAL	EPOCH:96/200	LOSS:0.685948
TRAIN	EPOCH:97/200	LOSS:0.865799
VAL	EPOCH:97/200	LOSS:0.679133
TRAIN	EPOCH:98/200	LOSS:0.866045
VAL	EPOCH:98/200	LOSS:0.679399
TRAIN	EPOCH:99/200	LOSS:0.865897
VAL	EPOCH:99/200	LOSS:0.681128
TRAIN	EPOCH:100/200	LOSS:0.864867
VAL	EPOCH:100/200	LOSS:0.68138
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:101/200	LOSS:0.862688
VAL	EPOCH:101/200	LOSS:0.678907
TRAIN	EPOCH:102/200	LOSS:0.864762
VAL	EPOCH:102/200	LOSS:0.674288
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:103/200	LOSS:0.862468
VAL	EPOCH:103/200	LOSS:0.681559
TRAIN	EPOCH:104/200	LOSS:0.861256
VAL	EPOCH:104/200	LOSS:0.676624
TRAIN	EPOCH:105/200	LOSS:0.8614
VAL	EPOCH:105/200	LOSS:0.676112
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:106/200	LOSS:0.860471
VAL	EPOCH:106/200	LOSS:0.676534
TRAIN	EPOCH:107/200	LOSS:0.861599
VAL	EPOCH:107/200	LOSS:0.673024
TRAIN	EPOCH:108/200	LOSS:0.860006
VAL	EPOCH:108/200	LOSS:0.678694
TRAIN	EPOCH:109/200	LOSS:0.85732
VAL	EPOCH:109/200	LOSS:0.676775
TRAIN	EPOCH:110/200	LOSS:0.860005
VAL	EPOCH:110/200	LOSS:0.684379
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:111/200	LOSS:0.856583
VAL	EPOCH:111/200	LOSS:0.678336
TRAIN	EPOCH:112/200	LOSS:0.857147
VAL	EPOCH:112/200	LOSS:0.671668
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:113/200	LOSS:0.855812
VAL	EPOCH:113/200	LOSS:0.673572
TRAIN	EPOCH:114/200	LOSS:0.855389
VAL	EPOCH:114/200	LOSS:0.67187
TRAIN	EPOCH:115/200	LOSS:0.85443
VAL	EPOCH:115/200	LOSS:0.671489
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:116/200	LOSS:0.855314
VAL	EPOCH:116/200	LOSS:0.671027
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:117/200	LOSS:0.854823
VAL	EPOCH:117/200	LOSS:0.680958
TRAIN	EPOCH:118/200	LOSS:0.853977
VAL	EPOCH:118/200	LOSS:0.672443
TRAIN	EPOCH:119/200	LOSS:0.852784
VAL	EPOCH:119/200	LOSS:0.673546
TRAIN	EPOCH:120/200	LOSS:0.852043
VAL	EPOCH:120/200	LOSS:0.671994
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:121/200	LOSS:0.851928
VAL	EPOCH:121/200	LOSS:0.673074
TRAIN	EPOCH:122/200	LOSS:0.850999
VAL	EPOCH:122/200	LOSS:0.670982
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:123/200	LOSS:0.848563
VAL	EPOCH:123/200	LOSS:0.673164
TRAIN	EPOCH:124/200	LOSS:0.849463
VAL	EPOCH:124/200	LOSS:0.66991
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:125/200	LOSS:0.851599
VAL	EPOCH:125/200	LOSS:0.676608
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:126/200	LOSS:0.847222
VAL	EPOCH:126/200	LOSS:0.663561
TRAIN	EPOCH:127/200	LOSS:0.847851
VAL	EPOCH:127/200	LOSS:0.663371
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:128/200	LOSS:0.847826
VAL	EPOCH:128/200	LOSS:0.670582
TRAIN	EPOCH:129/200	LOSS:0.848853
VAL	EPOCH:129/200	LOSS:0.662328
TRAIN	EPOCH:130/200	LOSS:0.846453
VAL	EPOCH:130/200	LOSS:0.667622
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:131/200	LOSS:0.844462
VAL	EPOCH:131/200	LOSS:0.660125
TRAIN	EPOCH:132/200	LOSS:0.846905
VAL	EPOCH:132/200	LOSS:0.667275
TRAIN	EPOCH:133/200	LOSS:0.844248
VAL	EPOCH:133/200	LOSS:0.669922
TRAIN	EPOCH:134/200	LOSS:0.84528
VAL	EPOCH:134/200	LOSS:0.661678
TRAIN	EPOCH:135/200	LOSS:0.845903
VAL	EPOCH:135/200	LOSS:0.664453
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:136/200	LOSS:0.842564
VAL	EPOCH:136/200	LOSS:0.657592
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:137/200	LOSS:0.842421
VAL	EPOCH:137/200	LOSS:0.666963
TRAIN	EPOCH:138/200	LOSS:0.843588
VAL	EPOCH:138/200	LOSS:0.662813
TRAIN	EPOCH:139/200	LOSS:0.842141
VAL	EPOCH:139/200	LOSS:0.661529
TRAIN	EPOCH:140/200	LOSS:0.842686
VAL	EPOCH:140/200	LOSS:0.659974
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:141/200	LOSS:0.842186
VAL	EPOCH:141/200	LOSS:0.653883
TRAIN	EPOCH:142/200	LOSS:0.841134
VAL	EPOCH:142/200	LOSS:0.655746
TRAIN	EPOCH:143/200	LOSS:0.839921
VAL	EPOCH:143/200	LOSS:0.657313
TRAIN	EPOCH:144/200	LOSS:0.839904
VAL	EPOCH:144/200	LOSS:0.6625
TRAIN	EPOCH:145/200	LOSS:0.840638
VAL	EPOCH:145/200	LOSS:0.660827
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:146/200	LOSS:0.838329
VAL	EPOCH:146/200	LOSS:0.655114
TRAIN	EPOCH:147/200	LOSS:0.841067
VAL	EPOCH:147/200	LOSS:0.65959
TRAIN	EPOCH:148/200	LOSS:0.839597
VAL	EPOCH:148/200	LOSS:0.653895
TRAIN	EPOCH:149/200	LOSS:0.837979
VAL	EPOCH:149/200	LOSS:0.656479
TRAIN	EPOCH:150/200	LOSS:0.839609
VAL	EPOCH:150/200	LOSS:0.661569
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:151/200	LOSS:0.83716
VAL	EPOCH:151/200	LOSS:0.654095
TRAIN	EPOCH:152/200	LOSS:0.837125
VAL	EPOCH:152/200	LOSS:0.65174
TRAIN	EPOCH:153/200	LOSS:0.836917
VAL	EPOCH:153/200	LOSS:0.651291
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:154/200	LOSS:0.83846
VAL	EPOCH:154/200	LOSS:0.657581
TRAIN	EPOCH:155/200	LOSS:0.834886
VAL	EPOCH:155/200	LOSS:0.651712
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:156/200	LOSS:0.835333
VAL	EPOCH:156/200	LOSS:0.656613
TRAIN	EPOCH:157/200	LOSS:0.835167
VAL	EPOCH:157/200	LOSS:0.650513
TRAIN	EPOCH:158/200	LOSS:0.833765
VAL	EPOCH:158/200	LOSS:0.653284
TRAIN	EPOCH:159/200	LOSS:0.832884
VAL	EPOCH:159/200	LOSS:0.649791
TRAIN	EPOCH:160/200	LOSS:0.834381
VAL	EPOCH:160/200	LOSS:0.652834
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:161/200	LOSS:0.833812
VAL	EPOCH:161/200	LOSS:0.657081
TRAIN	EPOCH:162/200	LOSS:0.834025
VAL	EPOCH:162/200	LOSS:0.649913
TRAIN	EPOCH:163/200	LOSS:0.833561
VAL	EPOCH:163/200	LOSS:0.653406
TRAIN	EPOCH:164/200	LOSS:0.832579
VAL	EPOCH:164/200	LOSS:0.650829
TRAIN	EPOCH:165/200	LOSS:0.833299
VAL	EPOCH:165/200	LOSS:0.650778
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:166/200	LOSS:0.831923
VAL	EPOCH:166/200	LOSS:0.652743
TRAIN	EPOCH:167/200	LOSS:0.831941
VAL	EPOCH:167/200	LOSS:0.644358
TRAIN	EPOCH:168/200	LOSS:0.832966
VAL	EPOCH:168/200	LOSS:0.654931
TRAIN	EPOCH:169/200	LOSS:0.83247
VAL	EPOCH:169/200	LOSS:0.65241
TRAIN	EPOCH:170/200	LOSS:0.829793
VAL	EPOCH:170/200	LOSS:0.645072
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:171/200	LOSS:0.831709
VAL	EPOCH:171/200	LOSS:0.648737
TRAIN	EPOCH:172/200	LOSS:0.829324
VAL	EPOCH:172/200	LOSS:0.648212
TRAIN	EPOCH:173/200	LOSS:0.830324
VAL	EPOCH:173/200	LOSS:0.649293
TRAIN	EPOCH:174/200	LOSS:0.830593
VAL	EPOCH:174/200	LOSS:0.647796
TRAIN	EPOCH:175/200	LOSS:0.82907
VAL	EPOCH:175/200	LOSS:0.643739
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:176/200	LOSS:0.828829
VAL	EPOCH:176/200	LOSS:0.650738
TRAIN	EPOCH:177/200	LOSS:0.829346
VAL	EPOCH:177/200	LOSS:0.648699
TRAIN	EPOCH:178/200	LOSS:0.829435
VAL	EPOCH:178/200	LOSS:0.652925
TRAIN	EPOCH:179/200	LOSS:0.829142
VAL	EPOCH:179/200	LOSS:0.647301
TRAIN	EPOCH:180/200	LOSS:0.82808
VAL	EPOCH:180/200	LOSS:0.654812
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:181/200	LOSS:0.828069
VAL	EPOCH:181/200	LOSS:0.645649
TRAIN	EPOCH:182/200	LOSS:0.826873
VAL	EPOCH:182/200	LOSS:0.647198
TRAIN	EPOCH:183/200	LOSS:0.828507
VAL	EPOCH:183/200	LOSS:0.644441
TRAIN	EPOCH:184/200	LOSS:0.826703
VAL	EPOCH:184/200	LOSS:0.641852
TRAIN	EPOCH:185/200	LOSS:0.826758
VAL	EPOCH:185/200	LOSS:0.644431
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:186/200	LOSS:0.826213
VAL	EPOCH:186/200	LOSS:0.643027
TRAIN	EPOCH:187/200	LOSS:0.826131
VAL	EPOCH:187/200	LOSS:0.645007
TRAIN	EPOCH:188/200	LOSS:0.82496
VAL	EPOCH:188/200	LOSS:0.645531
TRAIN	EPOCH:189/200	LOSS:0.82659
VAL	EPOCH:189/200	LOSS:0.644639
TRAIN	EPOCH:190/200	LOSS:0.825638
VAL	EPOCH:190/200	LOSS:0.641174
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:191/200	LOSS:0.82558
VAL	EPOCH:191/200	LOSS:0.639788
TRAIN	EPOCH:192/200	LOSS:0.82437
VAL	EPOCH:192/200	LOSS:0.6404
TRAIN	EPOCH:193/200	LOSS:0.824261
VAL	EPOCH:193/200	LOSS:0.63901
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:194/200	LOSS:0.825462
VAL	EPOCH:194/200	LOSS:0.640908
TRAIN	EPOCH:195/200	LOSS:0.824533
VAL	EPOCH:195/200	LOSS:0.641902
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:196/200	LOSS:0.822883
VAL	EPOCH:196/200	LOSS:0.641533
TRAIN	EPOCH:197/200	LOSS:0.823055
VAL	EPOCH:197/200	LOSS:0.645447
TRAIN	EPOCH:198/200	LOSS:0.824994
VAL	EPOCH:198/200	LOSS:0.642904
TRAIN	EPOCH:199/200	LOSS:0.824884
VAL	EPOCH:199/200	LOSS:0.640789
Loading data...
Creating splits...
Creating model...
TransfModel(
  (embedding): Embedding(63, 64)
  (encoder_layer): TransformerEncoderLayer(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
    )
    (linear1): Linear(in_features=64, out_features=64, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
    (linear2): Linear(in_features=64, out_features=64, bias=True)
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-2): 3 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=64, bias=True)
        (dropout): Dropout(p=0.2, inplace=False)
        (linear2): Linear(in_features=64, out_features=64, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (positional_encoding): PositionalEncoding(
    (dropout): Dropout(p=0.2, inplace=False)
  )
  (prediction_layer): Linear(in_features=64, out_features=63, bias=True)
  (softmax): Softmax(dim=-1)
)
Using CUDA.
Training started.
TRAIN	EPOCH:0/200	LOSS:2.203424
VAL	EPOCH:0/200	LOSS:1.737923
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:1/200	LOSS:1.732693
VAL	EPOCH:1/200	LOSS:1.547062
TRAIN	EPOCH:2/200	LOSS:1.602253
VAL	EPOCH:2/200	LOSS:1.407691
TRAIN	EPOCH:3/200	LOSS:1.50435
VAL	EPOCH:3/200	LOSS:1.29132
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:4/200	LOSS:1.431587
VAL	EPOCH:4/200	LOSS:1.198328
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:5/200	LOSS:1.371607
VAL	EPOCH:5/200	LOSS:1.113113
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:6/200	LOSS:1.324203
VAL	EPOCH:6/200	LOSS:1.063272
TRAIN	EPOCH:7/200	LOSS:1.278931
VAL	EPOCH:7/200	LOSS:1.013373
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:8/200	LOSS:1.24283
VAL	EPOCH:8/200	LOSS:0.984619
TRAIN	EPOCH:9/200	LOSS:1.213549
VAL	EPOCH:9/200	LOSS:0.950581
TRAIN	EPOCH:10/200	LOSS:1.186648
VAL	EPOCH:10/200	LOSS:0.926746
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:11/200	LOSS:1.164444
VAL	EPOCH:11/200	LOSS:0.901904
TRAIN	EPOCH:12/200	LOSS:1.141186
VAL	EPOCH:12/200	LOSS:0.883111
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:13/200	LOSS:1.125098
VAL	EPOCH:13/200	LOSS:0.871575
TRAIN	EPOCH:14/200	LOSS:1.108228
VAL	EPOCH:14/200	LOSS:0.86608
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:15/200	LOSS:1.096093
VAL	EPOCH:15/200	LOSS:0.852202
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:16/200	LOSS:1.080026
VAL	EPOCH:16/200	LOSS:0.838862
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:17/200	LOSS:1.072185
VAL	EPOCH:17/200	LOSS:0.828444
TRAIN	EPOCH:18/200	LOSS:1.059515
VAL	EPOCH:18/200	LOSS:0.831382
TRAIN	EPOCH:19/200	LOSS:1.051492
VAL	EPOCH:19/200	LOSS:0.826048
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:20/200	LOSS:1.03958
VAL	EPOCH:20/200	LOSS:0.812255
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:21/200	LOSS:1.032239
VAL	EPOCH:21/200	LOSS:0.809774
TRAIN	EPOCH:22/200	LOSS:1.025573
VAL	EPOCH:22/200	LOSS:0.797024
TRAIN	EPOCH:23/200	LOSS:1.018151
VAL	EPOCH:23/200	LOSS:0.790623
TRAIN	EPOCH:24/200	LOSS:1.012591
VAL	EPOCH:24/200	LOSS:0.785608
TRAIN	EPOCH:25/200	LOSS:1.004965
VAL	EPOCH:25/200	LOSS:0.788044
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:26/200	LOSS:1.000272
VAL	EPOCH:26/200	LOSS:0.783414
TRAIN	EPOCH:27/200	LOSS:0.991826
VAL	EPOCH:27/200	LOSS:0.774161
TRAIN	EPOCH:28/200	LOSS:0.98884
VAL	EPOCH:28/200	LOSS:0.77456
TRAIN	EPOCH:29/200	LOSS:0.983132
VAL	EPOCH:29/200	LOSS:0.779897
TRAIN	EPOCH:30/200	LOSS:0.980321
VAL	EPOCH:30/200	LOSS:0.773386
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:31/200	LOSS:0.973936
VAL	EPOCH:31/200	LOSS:0.770397
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:32/200	LOSS:0.969961
VAL	EPOCH:32/200	LOSS:0.760272
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:33/200	LOSS:0.966089
VAL	EPOCH:33/200	LOSS:0.760839
TRAIN	EPOCH:34/200	LOSS:0.962245
VAL	EPOCH:34/200	LOSS:0.752825
TRAIN	EPOCH:35/200	LOSS:0.957574
VAL	EPOCH:35/200	LOSS:0.753415
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:36/200	LOSS:0.953364
VAL	EPOCH:36/200	LOSS:0.752767
TRAIN	EPOCH:37/200	LOSS:0.951013
VAL	EPOCH:37/200	LOSS:0.752339
TRAIN	EPOCH:38/200	LOSS:0.949692
VAL	EPOCH:38/200	LOSS:0.749656
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:39/200	LOSS:0.942704
VAL	EPOCH:39/200	LOSS:0.740595
TRAIN	EPOCH:40/200	LOSS:0.94038
VAL	EPOCH:40/200	LOSS:0.744224
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:41/200	LOSS:0.938772
VAL	EPOCH:41/200	LOSS:0.74056
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:42/200	LOSS:0.935601
VAL	EPOCH:42/200	LOSS:0.739171
TRAIN	EPOCH:43/200	LOSS:0.932259
VAL	EPOCH:43/200	LOSS:0.741127
TRAIN	EPOCH:44/200	LOSS:0.930906
VAL	EPOCH:44/200	LOSS:0.737567
TRAIN	EPOCH:45/200	LOSS:0.927934
VAL	EPOCH:45/200	LOSS:0.738303
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:46/200	LOSS:0.924895
VAL	EPOCH:46/200	LOSS:0.72748
TRAIN	EPOCH:47/200	LOSS:0.922849
VAL	EPOCH:47/200	LOSS:0.7334
TRAIN	EPOCH:48/200	LOSS:0.92276
VAL	EPOCH:48/200	LOSS:0.727073
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:49/200	LOSS:0.920184
VAL	EPOCH:49/200	LOSS:0.725292
TRAIN	EPOCH:50/200	LOSS:0.918543
VAL	EPOCH:50/200	LOSS:0.726518
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:51/200	LOSS:0.915382
VAL	EPOCH:51/200	LOSS:0.721073
TRAIN	EPOCH:52/200	LOSS:0.9131
VAL	EPOCH:52/200	LOSS:0.716329
TRAIN	EPOCH:53/200	LOSS:0.911369
VAL	EPOCH:53/200	LOSS:0.720945
TRAIN	EPOCH:54/200	LOSS:0.912099
VAL	EPOCH:54/200	LOSS:0.725478
TRAIN	EPOCH:55/200	LOSS:0.909118
VAL	EPOCH:55/200	LOSS:0.722719
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:56/200	LOSS:0.906874
VAL	EPOCH:56/200	LOSS:0.717814
TRAIN	EPOCH:57/200	LOSS:0.906447
VAL	EPOCH:57/200	LOSS:0.718537
TRAIN	EPOCH:58/200	LOSS:0.902918
VAL	EPOCH:58/200	LOSS:0.708869
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:59/200	LOSS:0.90307
VAL	EPOCH:59/200	LOSS:0.711749
TRAIN	EPOCH:60/200	LOSS:0.899917
VAL	EPOCH:60/200	LOSS:0.708717
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:61/200	LOSS:0.899136
VAL	EPOCH:61/200	LOSS:0.709978
TRAIN	EPOCH:62/200	LOSS:0.898575
VAL	EPOCH:62/200	LOSS:0.708282
TRAIN	EPOCH:63/200	LOSS:0.897279
VAL	EPOCH:63/200	LOSS:0.704158
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:64/200	LOSS:0.895352
VAL	EPOCH:64/200	LOSS:0.70734
TRAIN	EPOCH:65/200	LOSS:0.896125
VAL	EPOCH:65/200	LOSS:0.706903
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:66/200	LOSS:0.893413
VAL	EPOCH:66/200	LOSS:0.707827
TRAIN	EPOCH:67/200	LOSS:0.891468
VAL	EPOCH:67/200	LOSS:0.708457
TRAIN	EPOCH:68/200	LOSS:0.891486
VAL	EPOCH:68/200	LOSS:0.701392
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:69/200	LOSS:0.890212
VAL	EPOCH:69/200	LOSS:0.705699
TRAIN	EPOCH:70/200	LOSS:0.886664
VAL	EPOCH:70/200	LOSS:0.70485
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:71/200	LOSS:0.888455
VAL	EPOCH:71/200	LOSS:0.698061
TRAIN	EPOCH:72/200	LOSS:0.886813
VAL	EPOCH:72/200	LOSS:0.702359
TRAIN	EPOCH:73/200	LOSS:0.887943
VAL	EPOCH:73/200	LOSS:0.7012
TRAIN	EPOCH:74/200	LOSS:0.885914
VAL	EPOCH:74/200	LOSS:0.700139
TRAIN	EPOCH:75/200	LOSS:0.884929
VAL	EPOCH:75/200	LOSS:0.701911
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:76/200	LOSS:0.883687
VAL	EPOCH:76/200	LOSS:0.700781
TRAIN	EPOCH:77/200	LOSS:0.882378
VAL	EPOCH:77/200	LOSS:0.69383
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:78/200	LOSS:0.879662
VAL	EPOCH:78/200	LOSS:0.692038
TRAIN	EPOCH:79/200	LOSS:0.87854
VAL	EPOCH:79/200	LOSS:0.69817
TRAIN	EPOCH:80/200	LOSS:0.879948
VAL	EPOCH:80/200	LOSS:0.697047
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:81/200	LOSS:0.878184
VAL	EPOCH:81/200	LOSS:0.699143
TRAIN	EPOCH:82/200	LOSS:0.878093
VAL	EPOCH:82/200	LOSS:0.69608
TRAIN	EPOCH:83/200	LOSS:0.877562
VAL	EPOCH:83/200	LOSS:0.691372
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:84/200	LOSS:0.875985
VAL	EPOCH:84/200	LOSS:0.688081
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:85/200	LOSS:0.874096
VAL	EPOCH:85/200	LOSS:0.703971
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:86/200	LOSS:0.873277
VAL	EPOCH:86/200	LOSS:0.686636
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:87/200	LOSS:0.872938
VAL	EPOCH:87/200	LOSS:0.685862
TRAIN	EPOCH:88/200	LOSS:0.871893
VAL	EPOCH:88/200	LOSS:0.692979
TRAIN	EPOCH:89/200	LOSS:0.873552
VAL	EPOCH:89/200	LOSS:0.698775
TRAIN	EPOCH:90/200	LOSS:0.870407
VAL	EPOCH:90/200	LOSS:0.686989
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:91/200	LOSS:0.870356
VAL	EPOCH:91/200	LOSS:0.684874
TRAIN	EPOCH:92/200	LOSS:0.870929
VAL	EPOCH:92/200	LOSS:0.692258
TRAIN	EPOCH:93/200	LOSS:0.868746
VAL	EPOCH:93/200	LOSS:0.691884
TRAIN	EPOCH:94/200	LOSS:0.867891
VAL	EPOCH:94/200	LOSS:0.681314
TRAIN	EPOCH:95/200	LOSS:0.866677
VAL	EPOCH:95/200	LOSS:0.678647
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:96/200	LOSS:0.867463
VAL	EPOCH:96/200	LOSS:0.685948
TRAIN	EPOCH:97/200	LOSS:0.865799
VAL	EPOCH:97/200	LOSS:0.679133
TRAIN	EPOCH:98/200	LOSS:0.866045
VAL	EPOCH:98/200	LOSS:0.679399
TRAIN	EPOCH:99/200	LOSS:0.865897
VAL	EPOCH:99/200	LOSS:0.681128
TRAIN	EPOCH:100/200	LOSS:0.864867
VAL	EPOCH:100/200	LOSS:0.68138
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:101/200	LOSS:0.862688
VAL	EPOCH:101/200	LOSS:0.678907
TRAIN	EPOCH:102/200	LOSS:0.864762
VAL	EPOCH:102/200	LOSS:0.674289
TRAIN	EPOCH:103/200	LOSS:0.862468
VAL	EPOCH:103/200	LOSS:0.681559
TRAIN	EPOCH:104/200	LOSS:0.861256
VAL	EPOCH:104/200	LOSS:0.676624
TRAIN	EPOCH:105/200	LOSS:0.8614
VAL	EPOCH:105/200	LOSS:0.676112
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:106/200	LOSS:0.860471
VAL	EPOCH:106/200	LOSS:0.676534
TRAIN	EPOCH:107/200	LOSS:0.861599
VAL	EPOCH:107/200	LOSS:0.673024
TRAIN	EPOCH:108/200	LOSS:0.860006
VAL	EPOCH:108/200	LOSS:0.678694
TRAIN	EPOCH:109/200	LOSS:0.85732
VAL	EPOCH:109/200	LOSS:0.676775
TRAIN	EPOCH:110/200	LOSS:0.860005
VAL	EPOCH:110/200	LOSS:0.684379
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:111/200	LOSS:0.856583
VAL	EPOCH:111/200	LOSS:0.678336
TRAIN	EPOCH:112/200	LOSS:0.857147
VAL	EPOCH:112/200	LOSS:0.671668
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:113/200	LOSS:0.855812
VAL	EPOCH:113/200	LOSS:0.673572
TRAIN	EPOCH:114/200	LOSS:0.855389
VAL	EPOCH:114/200	LOSS:0.67187
TRAIN	EPOCH:115/200	LOSS:0.85443
VAL	EPOCH:115/200	LOSS:0.671489
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:116/200	LOSS:0.855314
VAL	EPOCH:116/200	LOSS:0.671027
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:117/200	LOSS:0.854823
VAL	EPOCH:117/200	LOSS:0.680958
TRAIN	EPOCH:118/200	LOSS:0.853977
VAL	EPOCH:118/200	LOSS:0.672443
TRAIN	EPOCH:119/200	LOSS:0.852784
VAL	EPOCH:119/200	LOSS:0.673546
TRAIN	EPOCH:120/200	LOSS:0.852043
VAL	EPOCH:120/200	LOSS:0.671994
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:121/200	LOSS:0.851928
VAL	EPOCH:121/200	LOSS:0.673074
TRAIN	EPOCH:122/200	LOSS:0.850999
VAL	EPOCH:122/200	LOSS:0.670982
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:123/200	LOSS:0.848563
VAL	EPOCH:123/200	LOSS:0.673164
TRAIN	EPOCH:124/200	LOSS:0.849463
VAL	EPOCH:124/200	LOSS:0.66991
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:125/200	LOSS:0.851599
VAL	EPOCH:125/200	LOSS:0.676609
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:126/200	LOSS:0.847222
VAL	EPOCH:126/200	LOSS:0.663561
TRAIN	EPOCH:127/200	LOSS:0.847851
VAL	EPOCH:127/200	LOSS:0.663371
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:128/200	LOSS:0.847826
VAL	EPOCH:128/200	LOSS:0.670582
TRAIN	EPOCH:129/200	LOSS:0.848853
VAL	EPOCH:129/200	LOSS:0.662328
TRAIN	EPOCH:130/200	LOSS:0.846453
VAL	EPOCH:130/200	LOSS:0.667621
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:131/200	LOSS:0.844462
VAL	EPOCH:131/200	LOSS:0.660125
TRAIN	EPOCH:132/200	LOSS:0.846905
VAL	EPOCH:132/200	LOSS:0.667275
TRAIN	EPOCH:133/200	LOSS:0.844248
VAL	EPOCH:133/200	LOSS:0.669922
TRAIN	EPOCH:134/200	LOSS:0.84528
VAL	EPOCH:134/200	LOSS:0.661678
TRAIN	EPOCH:135/200	LOSS:0.845903
VAL	EPOCH:135/200	LOSS:0.664453
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:136/200	LOSS:0.842564
VAL	EPOCH:136/200	LOSS:0.657592
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:137/200	LOSS:0.842421
VAL	EPOCH:137/200	LOSS:0.666963
TRAIN	EPOCH:138/200	LOSS:0.843588
VAL	EPOCH:138/200	LOSS:0.662813
TRAIN	EPOCH:139/200	LOSS:0.842141
VAL	EPOCH:139/200	LOSS:0.661529
TRAIN	EPOCH:140/200	LOSS:0.842686
VAL	EPOCH:140/200	LOSS:0.659974
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:141/200	LOSS:0.842186
VAL	EPOCH:141/200	LOSS:0.653883
TRAIN	EPOCH:142/200	LOSS:0.841134
VAL	EPOCH:142/200	LOSS:0.655746
TRAIN	EPOCH:143/200	LOSS:0.839921
VAL	EPOCH:143/200	LOSS:0.657313
TRAIN	EPOCH:144/200	LOSS:0.839904
VAL	EPOCH:144/200	LOSS:0.6625
TRAIN	EPOCH:145/200	LOSS:0.840638
VAL	EPOCH:145/200	LOSS:0.660827
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:146/200	LOSS:0.838329
VAL	EPOCH:146/200	LOSS:0.655114
TRAIN	EPOCH:147/200	LOSS:0.841067
VAL	EPOCH:147/200	LOSS:0.65959
TRAIN	EPOCH:148/200	LOSS:0.839597
VAL	EPOCH:148/200	LOSS:0.653895
TRAIN	EPOCH:149/200	LOSS:0.837979
VAL	EPOCH:149/200	LOSS:0.656479
TRAIN	EPOCH:150/200	LOSS:0.839609
VAL	EPOCH:150/200	LOSS:0.661569
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:151/200	LOSS:0.83716
VAL	EPOCH:151/200	LOSS:0.654095
TRAIN	EPOCH:152/200	LOSS:0.837125
VAL	EPOCH:152/200	LOSS:0.65174
TRAIN	EPOCH:153/200	LOSS:0.836917
VAL	EPOCH:153/200	LOSS:0.651291
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:154/200	LOSS:0.83846
VAL	EPOCH:154/200	LOSS:0.657581
TRAIN	EPOCH:155/200	LOSS:0.834886
VAL	EPOCH:155/200	LOSS:0.651712
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:156/200	LOSS:0.835333
VAL	EPOCH:156/200	LOSS:0.656613
TRAIN	EPOCH:157/200	LOSS:0.835167
VAL	EPOCH:157/200	LOSS:0.650513
TRAIN	EPOCH:158/200	LOSS:0.833765
VAL	EPOCH:158/200	LOSS:0.653284
TRAIN	EPOCH:159/200	LOSS:0.832884
VAL	EPOCH:159/200	LOSS:0.649791
TRAIN	EPOCH:160/200	LOSS:0.834381
VAL	EPOCH:160/200	LOSS:0.652834
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:161/200	LOSS:0.833812
VAL	EPOCH:161/200	LOSS:0.657081
TRAIN	EPOCH:162/200	LOSS:0.834024
VAL	EPOCH:162/200	LOSS:0.649913
TRAIN	EPOCH:163/200	LOSS:0.833561
VAL	EPOCH:163/200	LOSS:0.653406
TRAIN	EPOCH:164/200	LOSS:0.832579
VAL	EPOCH:164/200	LOSS:0.650829
TRAIN	EPOCH:165/200	LOSS:0.833299
VAL	EPOCH:165/200	LOSS:0.650778
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:166/200	LOSS:0.831923
VAL	EPOCH:166/200	LOSS:0.652743
TRAIN	EPOCH:167/200	LOSS:0.831941
VAL	EPOCH:167/200	LOSS:0.644358
TRAIN	EPOCH:168/200	LOSS:0.832966
VAL	EPOCH:168/200	LOSS:0.654931
TRAIN	EPOCH:169/200	LOSS:0.83247
VAL	EPOCH:169/200	LOSS:0.65241
TRAIN	EPOCH:170/200	LOSS:0.829793
VAL	EPOCH:170/200	LOSS:0.645072
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:171/200	LOSS:0.831709
VAL	EPOCH:171/200	LOSS:0.648737
TRAIN	EPOCH:172/200	LOSS:0.829324
VAL	EPOCH:172/200	LOSS:0.648212
TRAIN	EPOCH:173/200	LOSS:0.830324
VAL	EPOCH:173/200	LOSS:0.649293
TRAIN	EPOCH:174/200	LOSS:0.830593
VAL	EPOCH:174/200	LOSS:0.647795
TRAIN	EPOCH:175/200	LOSS:0.82907
VAL	EPOCH:175/200	LOSS:0.643739
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:176/200	LOSS:0.828829
VAL	EPOCH:176/200	LOSS:0.650738
TRAIN	EPOCH:177/200	LOSS:0.829346
VAL	EPOCH:177/200	LOSS:0.648699
TRAIN	EPOCH:178/200	LOSS:0.829435
VAL	EPOCH:178/200	LOSS:0.652925
TRAIN	EPOCH:179/200	LOSS:0.829142
VAL	EPOCH:179/200	LOSS:0.647301
TRAIN	EPOCH:180/200	LOSS:0.82808
VAL	EPOCH:180/200	LOSS:0.654812
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:181/200	LOSS:0.828069
VAL	EPOCH:181/200	LOSS:0.645649
TRAIN	EPOCH:182/200	LOSS:0.826873
VAL	EPOCH:182/200	LOSS:0.647198
TRAIN	EPOCH:183/200	LOSS:0.828507
VAL	EPOCH:183/200	LOSS:0.644441
TRAIN	EPOCH:184/200	LOSS:0.826703
VAL	EPOCH:184/200	LOSS:0.641852
TRAIN	EPOCH:185/200	LOSS:0.826758
VAL	EPOCH:185/200	LOSS:0.644431
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:186/200	LOSS:0.826213
VAL	EPOCH:186/200	LOSS:0.643027
TRAIN	EPOCH:187/200	LOSS:0.826131
VAL	EPOCH:187/200	LOSS:0.645007
TRAIN	EPOCH:188/200	LOSS:0.82496
VAL	EPOCH:188/200	LOSS:0.645531
TRAIN	EPOCH:189/200	LOSS:0.82659
VAL	EPOCH:189/200	LOSS:0.644639
TRAIN	EPOCH:190/200	LOSS:0.825638
VAL	EPOCH:190/200	LOSS:0.641174
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:191/200	LOSS:0.82558
VAL	EPOCH:191/200	LOSS:0.639788
TRAIN	EPOCH:192/200	LOSS:0.82437
VAL	EPOCH:192/200	LOSS:0.6404
TRAIN	EPOCH:193/200	LOSS:0.824261
VAL	EPOCH:193/200	LOSS:0.63901
Lowest loss model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/best.pytorch
TRAIN	EPOCH:194/200	LOSS:0.825462
VAL	EPOCH:194/200	LOSS:0.640908
TRAIN	EPOCH:195/200	LOSS:0.824533
VAL	EPOCH:195/200	LOSS:0.641902
Model saved at ./transf_l=3_es=64_hs=64_d=0.2_e=200_lr=0.001_bs=16_ah=4/checkpoint.pytorch
TRAIN	EPOCH:196/200	LOSS:0.822883
VAL	EPOCH:196/200	LOSS:0.641533
TRAIN	EPOCH:197/200	LOSS:0.823055
VAL	EPOCH:197/200	LOSS:0.645447
TRAIN	EPOCH:198/200	LOSS:0.824994
VAL	EPOCH:198/200	LOSS:0.642904
TRAIN	EPOCH:199/200	LOSS:0.824884
VAL	EPOCH:199/200	LOSS:0.640789
